import json
import sys
import asyncio
from typing import Dict, List, Any, Optional, Tuple, AsyncGenerator
from datetime import datetime
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
import re

from ..models.models import StreamingAgentState, SearchResult
from .worker_agents import DataGathererAgent, ProcessorAgent
from sentence_transformers import SentenceTransformer

# --- í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ---
PERSONA_PROMPTS = {}
try:
    with open("agents/prompts/persona_prompts.json", "r", encoding="utf-8") as f:
        PERSONA_PROMPTS = json.load(f)
    print("OrchestratorAgent: í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì„±ê³µ.")
except FileNotFoundError:
    print("ê²½ê³ : persona_prompts.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
except json.JSONDecodeError:
    print("ê²½ê³ : persona_prompts.json íŒŒì¼ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
# -----------------------------

class TriageAgent:
    """ìš”ì²­ ë¶„ë¥˜ ë° ë¼ìš°íŒ… ë‹´ë‹¹ Agent"""

    def __init__(self, model: str = "gemini-2.5-flash-lite", temperature: float = 0.1):
        self.llm = ChatGoogleGenerativeAI(model=model, temperature=temperature)

    async def classify_request(self, query: str, state: StreamingAgentState) -> StreamingAgentState:
        """ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ flow_type ê²°ì •"""
        print(f"\n>> Triage: ìš”ì²­ ë¶„ë¥˜ ì‹œì‘ - '{query}'")
        sys.stdout.flush()

        classification_prompt = f"""
ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì²˜ë¦¬ ë°©ì‹ì„ ê²°ì •í•˜ì„¸ìš”:

ì‚¬ìš©ì ìš”ì²­: {query}

ë¶„ë¥˜ ê¸°ì¤€:
1. **chat**: ê°„ë‹¨í•œ ì§ˆë¬¸, ì¼ë°˜ì ì¸ ëŒ€í™”, ë‹µë‹´, ê·¸ë¦¬ê³  ê°„ë‹¨í•œ Web Searchë‚˜, ë‚´ë¶€ ì •ë³´ë¥¼ ì¡°íšŒí•˜ì—¬ ë‹µë³€í•  ìˆ˜ ìˆëŠ” ê²½ìš°
   - ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤", "ê°„ë‹¨í•œ ì„¤ëª… ìš”ì²­", "ìµœê·¼ ~ ì‹œì„¸ ì•Œë ¤ì¤˜", "ìµœê·¼ ì´ìŠˆ Top 10ì´ ë­ì•¼?"

2. **task**: ë³µí•©ì ì¸ ë¶„ì„, ë°ì´í„° ìˆ˜ì§‘, ë¦¬í¬íŠ¸ ìƒì„±ì´ í•„ìš”, ì •í™•íˆëŠ” ì—¬ëŸ¬ ì„¹ì…˜ì— ê±¸ì¹œ ë³´ê³ ì„œ ìƒì„±ì´ í•„ìš”í•œ ì§ˆë¬¸ì¼ ê²½ìš° ë˜ëŠ”, ìì„¸í•œ ì˜ì–‘ ì •ë³´ì™€ ê°™ì€ RDBë¥¼ ì¡°íšŒ í•´ì•¼í•˜ëŠ” ì§ˆë¬¸ì¼ ê²½ìš°
   - ì˜ˆ: "~ë¥¼ ë¶„ì„í•´ì¤˜", "~ì— ëŒ€í•œ ìë£Œë¥¼ ì°¾ì•„ì¤˜", "ë³´ê³ ì„œ ì‘ì„±"

JSONìœ¼ë¡œ ì‘ë‹µ:
{{
    "flow_type": "chat" ë˜ëŠ” "task",
    "reasoning": "ë¶„ë¥˜ ê·¼ê±° ì„¤ëª…",
}}
"""

        try:
            response = await self.llm.ainvoke(classification_prompt)
            response_content = response.content.strip()

            # JSON ì‘ë‹µ ì¶”ì¶œ ì‹œë„
            classification = None
            try:
                # ì§ì ‘ íŒŒì‹± ì‹œë„
                classification = json.loads(response_content)
            except json.JSONDecodeError:
                # JSON ë¸”ë¡ ì°¾ê¸° ì‹œë„
                import re
                json_match = re.search(r'\{.*\}', response_content, re.DOTALL)
                if json_match:
                    classification = json.loads(json_match.group())
                else:
                    raise ValueError("Valid JSON not found in response")

            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ["flow_type", "reasoning"]
            for field in required_fields:
                if field not in classification:
                    raise ValueError(f"Missing required field: {field}")

            # state ì—…ë°ì´íŠ¸ (ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼ ë°©ì‹)
            state["flow_type"] = classification["flow_type"]
            state["metadata"].update({
                "triage_reasoning": classification["reasoning"],
                "classified_at": datetime.now().isoformat()
            })

            print(f"- ë¶„ë¥˜ ê²°ê³¼: {classification['flow_type']}")
            print(f"- ê·¼ê±°: {classification['reasoning']}")
            sys.stdout.flush()

        except Exception as e:
            print(f"- ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’(task) ì ìš©: {e}")
            sys.stdout.flush()
            state["flow_type"] = "task"  # ê¸°ë³¸ê°’
            state["metadata"].update({
                "triage_error": str(e),
                "classified_at": datetime.now().isoformat()
            })

        return state


class OrchestratorAgent:
    """ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ë° ì§€ëŠ¥í˜• ê³„íš ìˆ˜ë¦½ Agent"""

    def __init__(self, model: str = "gemini-2.5-flash-lite", temperature: float = 0.2):
        self.llm = ChatGoogleGenerativeAI(model=model, temperature=temperature)
        self.llm_openai_mini = ChatOpenAI(model="gpt-4o-mini", temperature=temperature)
        self.data_gatherer = DataGathererAgent()
        self.processor = ProcessorAgent()
        self.personas = PERSONA_PROMPTS
        

    # âœ… ì¶”ê°€: ì¼ê´€ëœ ìƒíƒœ ë©”ì‹œì§€ ìƒì„±ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
    def _create_status_event(self, stage: str, sub_stage: str, message: str, details: Optional[Dict] = None) -> Dict:
        """í‘œì¤€í™”ëœ ìƒíƒœ ì´ë²¤íŠ¸ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            "type": "status",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "agent": "OrchestratorAgent",
                "stage": stage,
                "sub_stage": sub_stage,
                "message": message,
                "details": details or {}
            }
        }

    async def _invoke_with_fallback(self, prompt: str, primary_model, fallback_model):
        """Gemini API rate limit ì‹œ OpenAIë¡œ fallback ì²˜ë¦¬"""
        try:
            result = await primary_model.ainvoke(prompt)
            return result
        except Exception as e:
            error_str = str(e).lower()
            rate_limit_indicators = ['429', 'quota', 'rate limit', 'exceeded', 'resource_exhausted']

            if any(indicator in error_str for indicator in rate_limit_indicators):
                print(f"OrchestratorAgent: Gemini API rate limit ê°ì§€, fallback ì‹œë„: {e}")
                if fallback_model:
                    try:
                        result = await fallback_model.ainvoke(prompt)
                        print("OrchestratorAgent: fallback ì„±ê³µ")
                        return result
                    except Exception as fallback_error:
                        print(f"OrchestratorAgent: fallbackë„ ì‹¤íŒ¨: {fallback_error}")
                        raise fallback_error
                else:
                    print("OrchestratorAgent: fallback ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                    raise e
            else:
                raise e

    def _inject_context_into_query(self, query: str, context: Dict[int, str]) -> str:
        """'[step-Xì˜ ê²°ê³¼]' í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‹¤ì œ ì»¨í…ìŠ¤íŠ¸ë¡œ êµì²´í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        match = re.search(r"\[step-(\d+)ì˜ ê²°ê³¼\]", query)
        if match:
            step_index = int(match.group(1))
            if step_index in context:
                print(f"  - {step_index}ë‹¨ê³„ ì»¨í…ìŠ¤íŠ¸ ì£¼ì…: '{context[step_index][:]}...'")
                # í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì´ì „ ë‹¨ê³„ì˜ ìš”ì•½ ê²°ê³¼ë¡œ ì¹˜í™˜
                return query.replace(match.group(0), f"ì´ì „ ë‹¨ê³„ ë¶„ì„ ê²°ê³¼: '{context[step_index]}'")
        return query

    async def generate_plan(self, state: StreamingAgentState) -> StreamingAgentState:
        """í˜ë¥´ì†Œë‚˜ ê´€ì ê³¼ ì˜ì¡´ì„±ì„ ë°˜ì˜í•˜ì—¬ ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš(Hybrid Model)ì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤."""
        print(f"\n>> Orchestrator: ì§€ëŠ¥í˜• ë‹¨ê³„ë³„ ê³„íš ìˆ˜ë¦½ ì‹œì‘")
        query = state["original_query"]
        current_date_str = datetime.now().strftime("%Yë…„ %mì›” %dì¼")

        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¶”ì¶œ
        persona_name = state.get("persona", "ê¸°ë³¸")
        persona_info = self.personas.get(persona_name, {})
        persona_description = persona_info.get("description", "ì¼ë°˜ì ì¸ ë¶„ì„ê°€")
        print(f"  - ê³„íš ìˆ˜ë¦½ì— '{persona_name}' í˜ë¥´ì†Œë‚˜ ê´€ì  ì ìš©")

        planning_prompt = f"""
ë‹¹ì‹ ì€ **'{persona_name}'ì˜ ìœ ëŠ¥í•œ AI ìˆ˜ì„ ë³´ì¢Œê´€**ì´ì **ì‹¤í–‰ ê³„íš ì„¤ê³„ ì „ë¬¸ê°€**ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” **'{persona_name}'ì˜ ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì°¾ì•„ë‚´ê¸° ìœ„í•œ, ë…¼ë¦¬ì ì´ê³  íš¨ìœ¨ì ì¸ ì‹¤í–‰ ê³„íš**ì„ ìˆ˜ë¦½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

**í•µì‹¬ ì„ë¬´ (ë°˜ë“œì‹œ ì¤€ìˆ˜í•  ê²ƒ)**:
1.  **í˜ë¥´ì†Œë‚˜ ê´€ì  ë°˜ì˜ (What to ask)**: ìƒì„±í•˜ëŠ” ëª¨ë“  í•˜ìœ„ ì§ˆë¬¸ì€ ì² ì €íˆ '{persona_name}'ì˜ ê´€ì‹¬ì‚¬ì— ë¶€í•©í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë“¤ì˜ í•µì‹¬ ë‹ˆì¦ˆ(ì˜ˆ: êµ¬ë§¤-ì›ê°€/ì‹œì„¸, ë§ˆì¼€íŒ…-íŠ¸ë Œë“œ/ì†Œë¹„ì, R&D-ì‹ ì›ë£Œ/ì„±ë¶„)ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ” ë° ì§‘ì¤‘í•˜ì„¸ìš”.
2.  **ë…¼ë¦¬ì  ê³„íš ìˆ˜ë¦½ (How to ask)**: í˜ë¥´ì†Œë‚˜ì˜ ê´€ì ì—ì„œ ë„ì¶œëœ ì§ˆë¬¸ë“¤ì˜ ì„ í›„ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬, ì˜ì¡´ì„±ì´ ìˆëŠ” ì‘ì—…ì€ ìˆœì°¨ì ìœ¼ë¡œ, ì—†ëŠ” ì‘ì—…ì€ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” ìµœì ì˜ ì‹¤í–‰ ë‹¨ê³„ë¥¼ ì„¤ê³„í•˜ì„¸ìš”.

**ì‚¬ìš©ì ì›ë³¸ ìš”ì²­**: "{query}"
**í˜„ì¬ ë‚ ì§œ**: {current_date_str}

---
**## ë³´ìœ  ë„êµ¬ ëª…ì„¸ì„œ ë° ì„ íƒ ê°€ì´ë“œ**

**1. rdb_search (PostgreSQL) - 1ìˆœìœ„ í™œìš©**
   - **ë°ì´í„° ì¢…ë¥˜**: ì •í˜• ë°ì´í„° (í…Œì´ë¸” ê¸°ë°˜: ì‹ìì¬ **ì˜ì–‘ì„±ë¶„**, ë†Â·ì¶•Â·ìˆ˜ì‚°ë¬¼ **ì‹œì„¸/ê°€ê²©/ê±°ë˜ëŸ‰** ë“± ìˆ˜ì¹˜ ë°ì´í„°).
   - **ì‚¬ìš© ì‹œì **: ì˜ì–‘ì„±ë¶„, í˜„ì¬ê°€ê²©, ì‹œì„¸ë³€ë™, ê°€ê²©ë¹„êµ, ìˆœìœ„/í‰ê· /í•©ê³„ ë“± **ì •í™•í•œ ìˆ˜ì¹˜ ì—°ì‚°**ì´ í•„ìš”í•  ë•Œ.
   - **íŠ¹ì§•**: ë‚ ì§œÂ·ì§€ì—­Â·í’ˆëª© ì»¬ëŸ¼ìœ¼ë¡œ **í•„í„°/ì§‘ê³„** ìµœì í™”. ë‹¤ì¤‘ ì¡°ê±´(where)ê³¼ group by, order byë¥¼ í†µí•œ **í†µê³„/ë­í‚¹** ì§ˆì˜ì— ì í•©. (ê´€ê³„ ê·¸ë˜í”„ íƒìƒ‰ì€ ë¹„ê¶Œì¥)
   - **ì˜ˆì‹œ ì§ˆì˜ ì˜ë„**: "ì‚¬ê³¼ ë¹„íƒ€ë¯¼C í•¨ëŸ‰", "ì§€ë‚œë‹¬ ì œì£¼ ê°ê·¤ í‰ê· ê°€", "ì „ë³µ ê°€ê²© ì¶”ì´", "ì˜ì–‘ì„±ë¶„ ìƒìœ„ TOP 10"

**2. vector_db_search (Elasticsearch) - 1ìˆœìœ„ í™œìš©**
   - **ë°ì´í„° ì¢…ë¥˜**: ë¹„ì •í˜• ë°ì´í„° (ë‰´ìŠ¤ê¸°ì‚¬, ë…¼ë¬¸, ë³´ê³ ì„œ ì „ë¬¸).
   - **ì‚¬ìš© ì‹œì **: ì‹œì¥ë¶„ì„, ì •ì±…ë¬¸ì„œ, íŠ¸ë Œë“œë¶„ì„, ë°°ê²½ì •ë³´, ì‹¤ë¬´ê°€ì´ë“œ ë“± ì„œìˆ í˜• ì •ë³´ë‚˜ ë¶„ì„ì´ í•„ìš”í•  ë•Œ.
   - **íŠ¹ì§•**: ì˜ë¯¸ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì§ˆë¬¸ì˜ ë§¥ë½ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ì°¾ì•„ì¤Œ.

**3. graph_db_search (Neo4j) - 1ìˆœìœ„ í™œìš©**
   - **ë°ì´í„° ì¢…ë¥˜**: **ê´€ê³„í˜•(ê·¸ë˜í”„) ë°ì´í„°**. ë…¸ë“œ: í’ˆëª©(ë†ì‚°ë¬¼/ìˆ˜ì‚°ë¬¼/ì¶•ì‚°ë¬¼), **Origin(ì›ì‚°ì§€: city/region)**, **Nutrient(ì˜ì–‘ì†Œ)**.
     ê´€ê³„: `(í’ˆëª©)-[:isFrom]->(Origin)`, `(í’ˆëª©)-[:hasNutrient]->(Nutrient)`. ìˆ˜ì‚°ë¬¼ì€ í’ˆëª© ë…¸ë“œì— `fishState`(í™œì–´/ì„ ì–´/ëƒ‰ë™/ê±´ì–´) ì†ì„± ì¡´ì¬.
   - **ì‚¬ìš© ì‹œì **: **í’ˆëª© â†” ì›ì‚°ì§€**, **í’ˆëª© â†” ì˜ì–‘ì†Œ**ì²˜ëŸ¼ **ì—”í‹°í‹° ê°„ ì—°ê²°**ì´ í•µì‹¬ì¼ ë•Œ. ì§€ì—­Â·ìƒíƒœ(fishState) ì¡°ê±´ì„ ì–¹ì€ **ì›ì‚°ì§€/íŠ¹ì‚°í’ˆ íƒìƒ‰**.
   - **íŠ¹ì§•**: ì§€ì‹ê·¸ë˜í”„ ê²½ë¡œ íƒìƒ‰ì— ìµœì í™”. í‚¤ì›Œë“œëŠ” **í’ˆëª©ëª…/ì§€ì—­ëª…/ì˜ì–‘ì†Œ/ìˆ˜ì‚°ë¬¼ ìƒíƒœ(fishState)**ë¡œ ê°„ê²°íˆ í‘œí˜„í•˜ê³ , ì§ˆë¬¸ì€ **"Aì˜ ì›ì‚°ì§€", "Aì˜ ì˜ì–‘ì†Œ", "ì§€ì—­ Bì˜ íŠ¹ì‚°í’ˆ/ì›ì‚°ì§€", "í™œì–´ Aì˜ ì›ì‚°ì§€"**ì²˜ëŸ¼ **ê´€ê³„ë¥¼ ëª…ì‹œ**í• ìˆ˜ë¡ ì •í™•ë„ ìƒìŠ¹.
   - **ì˜ˆì‹œ ì§ˆì˜ ì˜ë„**: "ì‚¬ê³¼ì˜ ì›ì‚°ì§€", "ì˜¤ë Œì§€ì˜ ì˜ì–‘ì†Œ", "ì œì£¼ë„ì˜ ê°ê·¤ ì›ì‚°ì§€", "í™œì–´ ë¬¸ì–´ ì›ì‚°ì§€", "ê²½ìƒë¶ë„ ì‚¬ê³¼ ì‚°ì§€ ì—°ê²°"

**4. web_search - 2ìˆœìœ„ (ìµœí›„ì˜ ìˆ˜ë‹¨)**
   - **ë°ì´í„° ì¢…ë¥˜**: ì‹¤ì‹œê°„ ìµœì‹  ì •ë³´, ì™¸ë¶€ ì¼ë°˜ ì§€ì‹.
   - **ì‚¬ìš© ì¡°ê±´**: ë‚´ë¶€ DB(rdb, vector, graph)ì˜ ì£¼ì œë¥¼ ë²—ì–´ë‚˜ê±°ë‚˜, ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ 'ë§¤ìš° ìµœì‹ ' ì •ë³´ë¥¼ ìš”êµ¬í•  ë•Œë§Œ ì‚¬ìš©.
   - **ì‚¬ìš© ê¸ˆì§€**: ë†ì¶•ìˆ˜ì‚°ë¬¼ ì‹œì„¸, ì˜ì–‘ì •ë³´, ì›ì‚°ì§€ ë“± ë‚´ë¶€ DBë¡œ ëª…ë°±íˆ í•´ê²° ê°€ëŠ¥í•œ ì§ˆë¬¸.

**ë„êµ¬ ì„ íƒ ìš°ì„ ìˆœìœ„:**
1. **ìˆ˜ì¹˜/í†µê³„ ë°ì´í„° (ì‹ìì¬ ì˜ì–‘ì„±ë¶„, ë†ì¶•ìˆ˜ì‚°ë¬¼ ì‹œì„¸)** â†’ `rdb_search`
2. **ê´€ê³„/ë¶„ë¥˜ ì •ë³´ (í’ˆëª©-ì›ì‚°ì§€, í’ˆëª©-ì˜ì–‘ì†Œ, ì§€ì—­-íŠ¹ì‚°í’ˆ, ìˆ˜ì‚°ë¬¼ ìƒíƒœë³„ ì›ì‚°ì§€)** â†’ `graph_db_search`
3. **ë¶„ì„/ì—°êµ¬ ë¬¸ì„œ (ì‹œì¥ë¶„ì„, ì†Œë¹„ì ì¡°ì‚¬)** â†’ `vector_db_search`
4. **ìµœì‹  íŠ¸ë Œë“œ/ì‹¤ì‹œê°„ ì •ë³´** â†’ `web_search`

**ê° ë„êµ¬ë³„ ì ìš© ì˜ˆì‹œ:**
- `rdb_search`: "ì‹ìì¬ ì˜ì–‘ì„±ë¶„", "ë†ì¶•ìˆ˜ì‚°ë¬¼ ì‹œì„¸", "ê°€ê²© ì¶”ì´/ë¹„êµ", "ì˜ì–‘ì„±ë¶„ ìƒìœ„ TOP"
- `graph_db_search`: "ì‚¬ê³¼ì˜ ì›ì‚°ì§€", "ì˜¤ë Œì§€ì˜ ì˜ì–‘ì†Œ", "ì œì£¼-ê°ê·¤ ê´€ê³„", "í™œì–´ ë¬¸ì–´ ì›ì‚°ì§€", "ì§€ì—­ë³„ íŠ¹ì‚°í’ˆ ì—°ê²°"
- `vector_db_search`: "ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œ", "ì†Œë¹„ì í–‰ë™ ì—°êµ¬", "ì •ì±… ë¬¸ì„œ"
- `web_search`: "2025ë…„ ìµœì‹  íŠ¸ë Œë“œ", "ì‹¤ì‹œê°„ ì—…ê³„ ë™í–¥"

---
**## ê³„íš ìˆ˜ë¦½ì„ ìœ„í•œ ë‹¨ê³„ë³„ ì‚¬ê³  í”„ë¡œì„¸ìŠ¤ (ë°˜ë“œì‹œ ì¤€ìˆ˜í•  ê²ƒ)**

**1ë‹¨ê³„: ëª©í‘œ ì¬í•´ì„**
- ì‚¬ìš©ìì˜ ì›ë³¸ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬, ìµœì¢… ëª©í‘œê°€ ë¬´ì—‡ì¸ì§€ **'{persona_name}'ì˜ ì…ì¥ì—ì„œ** ëª…í™•í•˜ê²Œ ì¬ì •ì˜í•©ë‹ˆë‹¤.
- (ì˜ˆ: ì›ë³¸ ìš”ì²­ì´ "ë§Œë‘ ì‹œì¥ ì¡°ì‚¬"ì¼ ë•Œ, í˜ë¥´ì†Œë‚˜ê°€ 'ë§ˆì¼€íŒ… ë‹´ë‹¹ì'ë¼ë©´ ìµœì¢… ëª©í‘œëŠ” 'ì‹ ì œí’ˆ ë§Œë‘ì˜ ì„±ê³µì ì¸ ì‹œì¥ ì§„ì…ì„ ìœ„í•œ ë§ˆì¼€íŒ… ì „ëµ ë³´ê³ ì„œ'ë¡œ êµ¬ì²´í™”í•©ë‹ˆë‹¤.)

**2ë‹¨ê³„: í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ì •ë³´ ì‹ë³„ ë° ì§ˆë¬¸ êµ¬ì²´í™”**
- 1ë‹¨ê³„ì—ì„œ ì¬ì •ì˜í•œ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´, **'{persona_name}'ê°€ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•  í•µì‹¬ í‚¤ì›Œë“œ(ì˜ˆ: êµ¬ë§¤ ë‹´ë‹¹ì-ì›ê°€/ì‹œì„¸, ë§ˆì¼€í„°-íŠ¸ë Œë“œ/ì†Œë¹„ì, R&D-ì‹ ì›ë£Œ/ì„±ë¶„)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ** í•„ìš”í•œ ì •ë³´ ì¡°ê°ë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤.
- ì‹ë³„ëœ ì •ë³´ ì¡°ê°ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, ê°ê° ì™„ê²°ëœ í˜•íƒœì˜ êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•©ë‹ˆë‹¤.
- ìƒì„±ëœ ëª¨ë“  í•˜ìœ„ ì§ˆë¬¸ì€ ì›ë³¸ ìš”ì²­ì˜ í•µì‹¬ ë§¥ë½(ì˜ˆ: 'ëŒ€í•œë¯¼êµ­', 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ')ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

**3ë‹¨ê³„: ì§ˆë¬¸ ê°„ ì˜ì¡´ì„± ë¶„ì„ (ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„)**
- ë¶„í•´ëœ ì§ˆë¬¸ë“¤ ê°„ì˜ ì„ í›„ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
- **"ì–´ë–¤ ì§ˆë¬¸ì´ ë‹¤ë¥¸ ì§ˆë¬¸ì˜ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ ì•Œì•„ì•¼ë§Œ ì œëŒ€ë¡œ ìˆ˜í–‰ë  ìˆ˜ ìˆëŠ”ê°€?"**ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
- ì˜ˆì‹œ: `Aë¶„ì•¼ì˜ ì‹œì¥ ê·œëª¨`ë¥¼ ì•Œì•„ì•¼ `Aë¶„ì•¼ì˜ ì£¼ìš” ê²½ìŸì‚¬`ë¥¼ ì¡°ì‚¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë‘ ì§ˆë¬¸ì€ ì˜ì¡´ì„±ì´ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´, `Aë¶„ì•¼ì˜ ì‹œì¥ ê·œëª¨`ì™€ `Bë¶„ì•¼ì˜ ì‹œì¥ ê·œëª¨` ì¡°ì‚¬ëŠ” ì„œë¡œ ë…ë¦½ì ì…ë‹ˆë‹¤.

**4ë‹¨ê³„: ì‹¤í–‰ ë‹¨ê³„ ê·¸ë£¹í™” (Grouping)**
- **Step 1**: ì„œë¡œ ì˜ì¡´ì„±ì´ ì—†ëŠ”, ê°€ì¥ ë¨¼ì € ìˆ˜í–‰ë˜ì–´ì•¼ í•  ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì§ˆë¬¸ë“¤ì„ ë°°ì¹˜í•©ë‹ˆë‹¤. (ì˜ˆ: ì‹œì¥ ê·œëª¨ ì¡°ì‚¬, ìµœì‹  íŠ¸ë Œë“œ ì¡°ì‚¬)
- **Step 2 ì´í›„**: ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼(`[step-Xì˜ ê²°ê³¼]` í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš©)ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì˜ì¡´ì„± ìˆëŠ” ì§ˆë¬¸ë“¤ì„ ë°°ì¹˜í•©ë‹ˆë‹¤. (ì˜ˆ: 1ë‹¨ê³„ì—ì„œ ì°¾ì€ 'ì„±ì¥ ë¶„ì•¼'ì˜ ê²½ìŸì‚¬ ì¡°ì‚¬)

**5ë‹¨ê³„: ê° ì§ˆë¬¸ì— ëŒ€í•œ ìµœì  ë„êµ¬ ì„ íƒ**
- 'ë³´ìœ  ë„êµ¬ ëª…ì„¸ì„œ'ë¥¼ ì°¸ê³ í•˜ì—¬ ê° í•˜ìœ„ ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ **ë‹¨ í•˜ë‚˜ë§Œ** ì‹ ì¤‘í•˜ê²Œ ì„ íƒí•©ë‹ˆë‹¤.
    - **"ì„±ë¶„", "ì˜ì–‘", "ì‹œì„¸", "ê°€ê²©"** í¬í•¨ â†’ `rdb_search`
    - **"ì›ì‚°ì§€", "ê´€ê³„", "ì œì¡°ì‚¬", "íŠ¹ì‚°í’ˆ", "fishState(í™œì–´/ì„ ì–´/ëƒ‰ë™/ê±´ì–´)"** í¬í•¨ â†’ `graph_db_search`
    - **"ë¶„ì„", "ì—°êµ¬", "ì¡°ì‚¬", "ë³´ê³ ì„œ", "ë™í–¥"** í¬í•¨ â†’ `vector_db_search`
    - **"ìµœì‹  íŠ¸ë Œë“œ", "ì‹¤ì‹œê°„ ì •ë³´", "2025ë…„"** ë“± ìµœì‹ ì„± ê°•ì¡° ì‹œ â†’ `web_search`

**6ë‹¨ê³„: ìµœì¢… JSON í˜•ì‹í™”**
- ìœ„ì—ì„œ ê²°ì •ëœ ëª¨ë“  ë‚´ìš©ì„ ì•„ë˜ 'ìµœì¢… ì¶œë ¥ í¬ë§·'ì— ë§ì¶° JSONìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
- **ì¤‘ìš”**: `sub_questions` í‚¤ëŠ” ë°˜ë“œì‹œ `execution_steps` ë°°ì—´ì˜ ê° ìš”ì†Œ ì•ˆì—ë§Œ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.

---
**## ê³„íš ìˆ˜ë¦½ ì˜ˆì‹œ**

**ìš”ì²­**: "ë§Œë‘ ì‹ ì œí’ˆ ê°œë°œì„ ìœ„í•´, í•´ì™¸ ìˆ˜ì¶œ ì‚¬ë¡€ì™€ ìµœì‹  ì‹í’ˆ íŠ¸ë Œë“œì— ë§ëŠ” ì›ë£Œë¥¼ ì¶”ì²œí•´ì¤˜."

**ìƒì„±ëœ ê³„íš(JSON)**:
{{
    "title": "ì‹ ì œí’ˆ ë§Œë‘ ê°œë°œì„ ìœ„í•œ ì‹œì¥ ì¡°ì‚¬ ë° ì›ë£Œ ì¶”ì²œ",
    "reasoning": "ì‹œì¥ ì¡°ì‚¬ì™€ íŠ¸ë Œë“œ ë¶„ì„ì„ 1ë‹¨ê³„ì—ì„œ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•œ ë’¤, ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 2ë‹¨ê³„ì—ì„œ êµ¬ì²´ì ì¸ ì›ë£Œë¥¼ ì¶”ì²œí•˜ëŠ” 2ë‹¨ê³„ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.",
    "execution_steps": [
        {{
            "step": 1,
            "reasoning": "ê¸°ë°˜ ì •ë³´ì¸ 'ìˆ˜ì¶œ ì‚¬ë¡€'ì™€ 'ìµœì‹  íŠ¸ë Œë“œ'ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.",
            "sub_questions": [
                {{"question": "ëŒ€í•œë¯¼êµ­ ëƒ‰ë™ë§Œë‘ í•´ì™¸ ìˆ˜ì¶œ ì„±ê³µ ì‚¬ë¡€ ë° ì¸ê¸° ì œí’ˆ íŠ¹ì§• ë¶„ì„", "tool": "vector_db_search"}},
                {{"question": "2025ë…„ ìµœì‹  ê¸€ë¡œë²Œ ì‹í’ˆ íŠ¸ë Œë“œ ë° ì†Œë¹„ì ì„ í˜¸ ì›ë£Œ", "tool": "web_search"}}
            ]
        }},
        {{
            "step": 2,
            "reasoning": "1ë‹¨ê³„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ì œí’ˆì— ì ìš©í•  êµ¬ì²´ì ì¸ ì›ë£Œë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.",
            "sub_questions": [
                {{"question": "[step-1ì˜ ê²°ê³¼]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, 'ê±´ê°• ë° ì›°ë¹™' íŠ¸ë Œë“œì— ë§ëŠ” ì‹ë¬¼ì„± ë§Œë‘ ì›ë£Œ ì¶”ì²œ", "tool": "vector_db_search"}},
                {{"question": "ì¶”ì²œëœ ì‹ ê·œ ì›ë£Œ(ì˜ˆ: ëŒ€ì²´ìœ¡)ì˜ ì˜ì–‘ì„±ë¶„ ì •ë³´", "tool": "rdb_search"}}
            ]
        }}
    ]
}}

---
**## ìµœì¢… ì¶œë ¥ í¬ë§·**

**ì¤‘ìš” ê·œì¹™**: ë‚´ë¶€ DBë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í™œìš©í•˜ê³ , web_searchëŠ” ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”. ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

{{
    "title": "ë¶„ì„ ë³´ê³ ì„œì˜ ì „ì²´ ì œëª©",
    "reasoning": "ì´ëŸ¬í•œ ë‹¨ê³„ë³„ ê³„íšì„ ìˆ˜ë¦½í•œ í•µì‹¬ì ì¸ ì´ìœ .",
    "execution_steps": [
        {{
            "step": 1,
            "reasoning": "1ë‹¨ê³„ ê³„íšì— ëŒ€í•œ ì„¤ëª…. ë³‘ë ¬ ì‹¤í–‰ë  ì‘ì—…ë“¤ì„ ê¸°ìˆ .",
            "sub_questions": [
                {{
                    "question": "1ë‹¨ê³„ì—ì„œ ë³‘ë ¬ë¡œ ì‹¤í–‰í•  ì²« ë²ˆì§¸ í•˜ìœ„ ì§ˆë¬¸",
                    "tool": "ì„ íƒëœ ë„êµ¬ ì´ë¦„"
                }},
                {{
                    "question": "1ë‹¨ê³„ì—ì„œ ë³‘ë ¬ë¡œ ì‹¤í–‰í•  ë‘ ë²ˆì§¸ í•˜ìœ„ ì§ˆë¬¸",
                    "tool": "ì„ íƒëœ ë„êµ¬ ì´ë¦„"
                }}
            ]
        }},
        {{
            "step": 2,
            "reasoning": "2ë‹¨ê³„ ê³„íšì— ëŒ€í•œ ì„¤ëª…. 1ë‹¨ê³„ ê²°ê³¼ì— ì˜ì¡´í•¨ì„ ëª…ì‹œ.",
            "sub_questions": [
                {{
                    "question": "2ë‹¨ê³„ì—ì„œ ì‹¤í–‰í•  í•˜ìœ„ ì§ˆë¬¸ (í•„ìš”ì‹œ '[step-1ì˜ ê²°ê³¼]' í¬í•¨)",
                    "tool": "ì„ íƒëœ ë„êµ¬ ì´ë¦„"
                }}
            ]
        }}
    ]
}}
"""

        try:
            response = await self.llm.ainvoke(planning_prompt)
            content = response.content.strip()

            json_match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
            if not json_match:
                json_match = re.search(r'\{.*\}', content, re.DOTALL)

            if json_match:
                json_str = json_match.group(1) if '```' in json_match.group(0) else json_match.group(0)
                plan = json.loads(json_str)
            else:
                raise ValueError("Valid JSON plan not found in response")

            print(f"  - ì§€ëŠ¥í˜• ë‹¨ê³„ë³„ ê³„íš ìƒì„± ì™„ë£Œ: {plan.get('title', 'ì œëª© ì—†ìŒ')}")
            print("  - ê³„íš JSON:")
            print(json.dumps(plan, ensure_ascii=False, indent=2))
            state["plan"] = plan

        except Exception as e:
            print(f"  - ì§€ëŠ¥í˜• ê³„íš ìƒì„± ì‹¤íŒ¨, ë‹¨ì¼ ë‹¨ê³„ë¡œ ì§ì ‘ ê²€ìƒ‰ ì‹¤í–‰: {e}")
            state["plan"] = {
                "title": f"{query} ë¶„ì„",
                "reasoning": "ì§€ëŠ¥í˜• ë‹¨ê³„ë³„ ê³„íš ìˆ˜ë¦½ì— ì‹¤íŒ¨í•˜ì—¬, ì‚¬ìš©ì ì›ë³¸ ì¿¼ë¦¬ë¡œ ì§ì ‘ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.",
                "execution_steps": [{
                    "step": 1,
                    "reasoning": "Fallback ì‹¤í–‰",
                    "sub_questions": [{"question": query, "tool": "vector_db_search"}]
                }]
            }

        return state



    # â­ í•µì‹¬ ìˆ˜ì •: ìš”ì•½ëœ ë‚´ìš©ì´ ì•„ë‹Œ ì „ì²´ ì›ë³¸ ë‚´ìš©ì„ LLMì—ê²Œ ì œê³µ
    async def _select_relevant_data_for_step(self, step_info: Dict, current_collected_data: List[SearchResult], query: str) -> List[int]:
        """í˜„ì¬ ë‹¨ê³„ì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„° ì¤‘ ê´€ë ¨ ìˆëŠ” ê²ƒë§Œ LLMì´ ì„ íƒ (ì „ì²´ ë‚´ìš© ê¸°ë°˜)"""

        step_title = f"Step {step_info['step']}"
        step_reasoning = step_info.get('reasoning', '')
        sub_questions = step_info.get('sub_questions', [])

        # â­ í•µì‹¬ ê°œì„ : ì „ì²´ ì›ë³¸ ë‚´ìš©ì„ LLMì—ê²Œ ì œê³µ (ìš”ì•½ ì—†ì´)
        full_data_context = ""
        for i, res in enumerate(current_collected_data):
            source = getattr(res, 'source', 'Unknown')
            title = getattr(res, 'title', 'No Title')
            content = getattr(res, 'content', '')  # â­ ì „ì²´ ë‚´ìš© (ìš”ì•½ ì•ˆí•¨)

            full_data_context += f"""
    --- ë°ì´í„° ì¸ë±ìŠ¤ [{i}] ---
    ì¶œì²˜: {source}
    ì œëª©: {title}
    ì „ì²´ ë‚´ìš©: {content}

    """

        # í˜„ì¬ ë‹¨ê³„ì˜ ì§ˆë¬¸ë“¤
        questions_summary = ""
        for sq in sub_questions:
            questions_summary += f"- {sq.get('question', '')} ({sq.get('tool', '')})\n"

        # â­ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê´€ë¦¬ (ì¤‘ìš”í•œ ë¶€ë¶„ë§Œ ì˜ë¼ë‚´ê¸°)
        # ë„ˆë¬´ ê¸¸ë©´ ê° ë°ì´í„°ë‹¹ ìµœëŒ€ 1000ìë¡œ ì œí•œ
        if len(full_data_context) > 15000:
            print(f"  - ì»¨í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸º ({len(full_data_context)}ì), ë°ì´í„°ë³„ 1000ìë¡œ ì œí•œ")

            truncated_context = ""
            for i, res in enumerate(current_collected_data):
                source = getattr(res, 'source', 'Unknown')
                title = getattr(res, 'title', 'No Title')
                content = getattr(res, 'content', '')[:1000]  # 1000ìë¡œ ì œí•œ

                truncated_context += f"""
    --- ë°ì´í„° ì¸ë±ìŠ¤ [{i}] ---
    ì¶œì²˜: {source}
    ì œëª©: {title}
    ë‚´ìš©: {content}{"..." if len(getattr(res, 'content', '')) > 1000 else ""}

    """
            full_data_context = truncated_context

        selection_prompt = f"""
    ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    í˜„ì¬ ë‹¨ê³„ì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„° ì¤‘ì—ì„œ **ë‹¤ìŒ ë‹¨ê³„ì—ì„œ í™œìš©í•  ê°€ì¹˜ê°€ ìˆëŠ” í•µì‹¬ ë°ì´í„°ë§Œ** ì„ íƒí•´ì£¼ì„¸ìš”.

    **ì „ì²´ ì‚¬ìš©ì ì§ˆë¬¸**: "{query}"

    **í˜„ì¬ ë‹¨ê³„ ì •ë³´**:
    - {step_title}: {step_reasoning}
    - ì‹¤í–‰í•œ ì§ˆë¬¸ë“¤:
    {questions_summary}

    **ìˆ˜ì§‘ëœ ì „ì²´ ë°ì´í„°** (ì „ì²´ ë‚´ìš© í¬í•¨):
    {full_data_context[:12000]}

    **ì„ íƒ ê¸°ì¤€**:
    1. **ë‚´ìš©ì„ ê¼¼ê¼¼íˆ ì½ê³ ** í˜„ì¬ ë‹¨ê³„ì˜ ëª©ì ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë°ì´í„°
    2. í–¥í›„ ë‹¨ê³„ì—ì„œ ì°¸ê³ í•  ê°€ì¹˜ê°€ ìˆëŠ” **ì‹¤ì§ˆì ì¸ ì •ë³´**ê°€ í¬í•¨ëœ ë°ì´í„°
    3. ì œëª©ë§Œ ë³´ê³  íŒë‹¨í•˜ì§€ ë§ê³  **ì‹¤ì œ ë‚´ìš©ì˜ ì§ˆê³¼ ê´€ë ¨ì„±** í™•ì¸
    4. ì¤‘ë³µë˜ê±°ë‚˜ ê´€ë ¨ì„±ì´ ë‚®ì€ ë°ì´í„°ëŠ” ì œì™¸
    5. ìµœëŒ€ 10ê°œ ì´ë‚´ë¡œ ì„ ë³„ (í’ˆì§ˆ ìš°ì„ )

    **ì¤‘ìš”**:
    - ê° ë°ì´í„°ì˜ **ì „ì²´ ë‚´ìš©ì„ ì½ê³ ** ê´€ë ¨ì„±ì„ íŒë‹¨í•˜ì„¸ìš”
    - ë‹¨ìˆœíˆ ì œëª©ì´ë‚˜ ì¶œì²˜ë§Œ ë³´ê³  ê²°ì •í•˜ì§€ ë§ˆì„¸ìš”
    - ì‹¤ì œë¡œ ìœ ìš©í•œ ì •ë³´ê°€ ë‹´ê¸´ ë°ì´í„°ë§Œ ì„ íƒí•˜ì„¸ìš”

    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
    {{
        "selected_indexes": [0, 2, 5, 8],
        "reasoning": "ê° ì„ íƒëœ ë°ì´í„°ê°€ ì™œ ì¤‘ìš”í•œì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…",
        "rejected_reason": "ì œì™¸ëœ ë°ì´í„°ë“¤ì˜ ì£¼ìš” ì œì™¸ ì´ìœ "
    }}
    """

        try:
            response = await self._invoke_with_fallback(
                selection_prompt,
                self.llm,
                self.llm_openai_mini
            )

            # JSON íŒŒì‹±
            result = json.loads(re.search(r'\{.*\}', response.content, re.DOTALL).group())
            selected_indexes = result.get("selected_indexes", [])
            reasoning = result.get("reasoning", "")
            rejected_reason = result.get("rejected_reason", "")

            # ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì¦
            max_index = len(current_collected_data) - 1
            valid_indexes = [idx for idx in selected_indexes if isinstance(idx, int) and 0 <= idx <= max_index]

            print(f"  - LLM ë°ì´í„° ì„ íƒ ì™„ë£Œ (ì „ì²´ ë‚´ìš© ê¸°ë°˜):")
            print(f"    ì„ íƒëœ ì¸ë±ìŠ¤: {valid_indexes}")
            print(f"    ì„ íƒ ì´ìœ : {reasoning}")
            print(f"    ì œì™¸ ì´ìœ : {rejected_reason}")

            # ì„ íƒëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            print(f"  - ì„ íƒëœ ë°ì´í„° ëª©ë¡:")
            for idx in valid_indexes[:5]:  # ì²˜ìŒ 5ê°œë§Œ
                data_item = current_collected_data[idx]
                print(f"    [{idx:2d}] {getattr(data_item, 'source', 'Unknown'):10s} | {getattr(data_item, 'title', 'No Title')[:60]}")

            return valid_indexes

        except Exception as e:
            print(f"  - LLM ë°ì´í„° ì„ íƒ ì‹¤íŒ¨: {e}")
            # fallback: í˜„ì¬ ë‹¨ê³„ì—ì„œ ìˆ˜ì§‘ëœ ëª¨ë“  ë°ì´í„° ìœ ì§€
            return list(range(len(current_collected_data)))


    async def _reselect_indexes_after_recollection(self, section_info: Dict, all_data: List[SearchResult], previous_selected: List[int], query: str) -> List[int]:
        """ë°ì´í„° ì¬ìˆ˜ì§‘ í›„ í•´ë‹¹ ì„¹ì…˜ì„ ìœ„í•œ ì¸ë±ìŠ¤ ì¬ì„ íƒ"""

        section_title = section_info.get('section_title', 'ì„¹ì…˜')
        content_type = section_info.get('content_type', 'synthesis')

        # ì „ì²´ ë°ì´í„° ìš”ì•½ (ì¸ë±ìŠ¤ í¬í•¨)
        data_summary = ""
        for i, res in enumerate(all_data):
            source = getattr(res, 'source', 'Unknown')
            title = getattr(res, 'title', 'No Title')
            content = getattr(res, 'content', '')[:150]

            # ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°ì¸ì§€ í‘œì‹œ
            is_new = i >= len(all_data) - 10  # ë§ˆì§€ë§‰ 10ê°œëŠ” ìƒˆ ë°ì´í„°ë¡œ ê°€ì •
            marker = "[NEW]" if is_new else ""

            data_summary += f"[{i:2d}]{marker} [{source}] {title}: {content}...\n"

        reselection_prompt = f"""
    ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ë°ì´í„° ì¬ìˆ˜ì§‘ì´ ì™„ë£Œëœ í›„, **íŠ¹ì • ì„¹ì…˜ì„ ìœ„í•´** ê°€ì¥ ì í•©í•œ ë°ì´í„°ë“¤ì„ ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.

    **ì „ì²´ ì‚¬ìš©ì ì§ˆë¬¸**: "{query}"

    **í˜„ì¬ ìƒì„±í•  ì„¹ì…˜ ì •ë³´**:
    - ì„¹ì…˜ ì œëª©: "{section_title}"
    - ì»¨í…ì¸  íƒ€ì…: "{content_type}"

    **ì´ì „ì— ì„ íƒëœ ì¸ë±ìŠ¤**: {previous_selected}

    **í˜„ì¬ ì „ì²´ ë°ì´í„°** (ì¸ë±ìŠ¤: 0ë¶€í„° ì‹œì‘, [NEW] = ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°):
    {data_summary[:6000]}

    **ì¬ì„ íƒ ê¸°ì¤€**:
    1. **"{section_title}" ì„¹ì…˜ ì£¼ì œì™€ ì§ì ‘ ê´€ë ¨ëœ ë°ì´í„° ìš°ì„  ì„ íƒ**
    2. **ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°([NEW])ë¥¼ ì ê·¹ì ìœ¼ë¡œ ê³ ë ¤** - ì´ ë°ì´í„°ë“¤ì€ í•´ë‹¹ ì„¹ì…˜ì„ ìœ„í•´ íŠ¹ë³„íˆ ìˆ˜ì§‘ëœ ê²ƒì„
    3. **ê¸°ì¡´ ì„ íƒëœ ë°ì´í„° ì¤‘ ì—¬ì „íˆ ê´€ë ¨ì„± ë†’ì€ ê²ƒë“¤ë„ ìœ ì§€**
    4. **ìµœëŒ€ 10ê°œ ì´ë‚´ë¡œ ì„ ë³„** (í’ˆì§ˆê³¼ ê´€ë ¨ì„± ìš°ì„ )
    5. **ì¤‘ë³µë˜ê±°ë‚˜ ìœ ì‚¬í•œ ë‚´ìš©ì€ ì œì™¸**

    **íŠ¹ë³„ ê³ ë ¤ì‚¬í•­**:
    - content_typeì´ "full_data_for_chart"ì¸ ê²½ìš°: ìˆ˜ì¹˜, í†µê³„, íŠ¸ë Œë“œ ë°ì´í„° ìš°ì„ 
    - content_typeì´ "synthesis"ì¸ ê²½ìš°: ë‹¤ì–‘í•œ ê´€ì ì˜ ì¢…í•©ì  ì •ë³´ ìš°ì„ 

    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
    {{
        "reselected_indexes": [2, 5, 8, 12, 15],
        "reasoning": "ì¬ì„ íƒ ì´ìœ ì™€ ìƒˆ ë°ì´í„° í™œìš© ë°©ì•ˆ",
        "new_data_count": 3,
        "kept_from_previous": 2
    }}
    """

        try:
            response = await self._invoke_with_fallback(
                reselection_prompt,
                self.llm,
                self.llm_openai_mini
            )

            # JSON íŒŒì‹±
            result = json.loads(re.search(r'\{.*\}', response.content, re.DOTALL).group())
            reselected_indexes = result.get("reselected_indexes", [])
            reasoning = result.get("reasoning", "")
            new_data_count = result.get("new_data_count", 0)
            kept_count = result.get("kept_from_previous", 0)

            # ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì¦
            max_index = len(all_data) - 1
            valid_indexes = [idx for idx in reselected_indexes if isinstance(idx, int) and 0 <= idx <= max_index]

            print(f"  - ì„¹ì…˜ '{section_title}' ì¸ë±ìŠ¤ ì¬ì„ íƒ ì™„ë£Œ:")
            print(f"    ì¬ì„ íƒëœ ì¸ë±ìŠ¤: {valid_indexes}")
            print(f"    ìƒˆ ë°ì´í„° í™œìš©: {new_data_count}ê°œ")
            print(f"    ê¸°ì¡´ ë°ì´í„° ìœ ì§€: {kept_count}ê°œ")
            print(f"    ì„ íƒ ì´ìœ : {reasoning}")

            return valid_indexes

        except Exception as e:
            print(f"  - ì¸ë±ìŠ¤ ì¬ì„ íƒ ì‹¤íŒ¨: {e}")
            # fallback: ê¸°ì¡´ ì„ íƒ + ìƒˆ ë°ì´í„° ì¼ë¶€
            fallback_indexes = previous_selected.copy()
            new_data_start = max(0, len(all_data) - 10)  # ë§ˆì§€ë§‰ 10ê°œëŠ” ìƒˆ ë°ì´í„°
            fallback_indexes.extend(list(range(new_data_start, len(all_data))))
            return list(set(fallback_indexes))  # ì¤‘ë³µ ì œê±°

    async def execute_report_workflow(self, state: StreamingAgentState) -> AsyncGenerator[str, None]:
        """ë‹¨ê³„ë³„ ê³„íšì— ë”°ë¼ ìˆœì°¨ì , ë³‘ë ¬ì ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ë° ë³´ê³ ì„œ ìƒì„±"""
        query = state["original_query"]

        # --- ì¶”ê°€: í˜ë¥´ì†Œë‚˜ í™•ì¸ ë° ìƒíƒœ ì•Œë¦¼ ---
        # ì‚¬ìš©ìê°€ ì„ íƒí•œ í˜ë¥´ì†Œë‚˜ê°€ stateì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
        # ì˜ˆ: state['persona'] = 'êµ¬ë§¤ ë‹´ë‹¹ì'
        selected_persona = state.get("persona")
        if not selected_persona or selected_persona not in self.personas:
            print(f"ê²½ê³ : ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì§€ì •ë˜ì§€ ì•Šì€ í˜ë¥´ì†Œë‚˜ ('{selected_persona}'). 'ê¸°ë³¸'ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
            selected_persona = "ê¸°ë³¸"
            state["persona"] = selected_persona

        yield self._create_status_event("PLANNING", "PERSONA_CONFIRMED", f"'{selected_persona}' í˜ë¥´ì†Œë‚˜ë¡œ ë³´ê³ ì„œ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        # ì°¨íŠ¸ ì¹´ìš´í„° ì´ˆê¸°í™”
        state['chart_counter'] = 0

        # 1. ë‹¨ê³„ë³„ ê³„íš ìˆ˜ë¦½
        yield self._create_status_event("PLANNING", "GENERATE_PLAN_START", "ë¶„ì„ ê³„íš ìˆ˜ë¦½ ì¤‘...")
        state_with_plan = await self.generate_plan(state)
        plan = state_with_plan.get("plan", {})

        yield {"type": "plan", "data": {"plan": plan}}

        yield self._create_status_event("PLANNING", "GENERATE_PLAN_COMPLETE", "ë¶„ì„ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ.", details={
            "plan_title": plan.get('title'),
            "plan_reasoning": plan.get('reasoning'),
            "step_count": len(plan.get("execution_steps", []))
        })

        await asyncio.sleep(0.01)

        # 2. ë‹¨ê³„ë³„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        execution_steps = plan.get("execution_steps", [])
        final_collected_data: List[SearchResult] = []
        step_results_context: Dict[int, str] = {}
        cumulative_selected_indexes: List[int] = []

        for i, step_info in enumerate(execution_steps):
            current_step_index = step_info["step"]
            yield self._create_status_event("GATHERING", "STEP_START", f"ë°ì´í„° ìˆ˜ì§‘ ({i + 1}/{len(execution_steps)}) ì‹œì‘.")

            tasks_for_this_step = []
            for sq in step_info.get("sub_questions", []):
                injected_query = self._inject_context_into_query(sq["question"], step_results_context)
                tasks_for_this_step.append({"tool": sq["tool"], "inputs": {"query": injected_query}})
            if not tasks_for_this_step:
                continue

            step_collected_data: List[SearchResult] = []
            async for event in self.data_gatherer.execute_parallel_streaming(tasks_for_this_step):
                if event["type"] == "search_results":
                    yield event
                elif event["type"] == "collection_complete":
                    step_collected_data = event["data"]["collected_data"]

            summary_of_step = " ".join([res.content for res in step_collected_data])
            step_results_context[current_step_index] = summary_of_step[:2000]
            final_collected_data.extend(step_collected_data)

            print(f">> {current_step_index}ë‹¨ê³„ ì™„ë£Œ: {len(step_collected_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘. (ì´ {len(final_collected_data)}ê°œ)")

            if len(final_collected_data) > 0:
                yield self._create_status_event("PROCESSING", "FILTER_DATA_START", "ìˆ˜ì§‘ ë°ì´í„° ì„ ë³„ ì¤‘...")

                # reasoningì„ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ selected_indexesë§Œ ë°›ìŠµë‹ˆë‹¤.
                selected_indexes = await self._select_relevant_data_for_step(
                    step_info, final_collected_data, state["original_query"]
                )

                yield self._create_status_event("PROCESSING", "FILTER_DATA_COMPLETE", f"í•µì‹¬ ë°ì´í„° {len(selected_indexes)}ê°œ ì„ ë³„ ì™„ë£Œ.", details={
                    "selected_indices": selected_indexes
                })
                cumulative_selected_indexes = sorted(list(set(cumulative_selected_indexes + selected_indexes)))

        # >> í•µì‹¬ ìˆ˜ì •: ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ë¥¼ í”„ë¡ íŠ¸ë¡œ ë¨¼ì € ì „ì†¡
        print(f"\n>> ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„± ë° ì „ì†¡")

        # ì „ì²´ ë°ì´í„°ë¥¼ ì¸ë±ìŠ¤:ë°ì´í„° í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        full_data_dict = {}
        print(f"\nğŸ” === FULL_DATA_DICT ìƒì„± ë””ë²„ê¹… ===")
        print(f"final_collected_data ì´ ê°œìˆ˜: {len(final_collected_data)}")

        for idx, data in enumerate(final_collected_data):
            full_data_dict[idx] = {
                "title": getattr(data, 'title', 'No Title'),
                "content": getattr(data, 'content', ''),
                "source": getattr(data, 'source', 'Unknown'),
                "url": getattr(data, 'url', ''),
                "source_url": getattr(data, 'source_url', ''),
                "score": getattr(data, 'score', 0.0),
                "document_type": getattr(data, 'document_type', 'unknown')
            }

            # ì²« 5ê°œì™€ ë§ˆì§€ë§‰ 5ê°œë§Œ ìƒì„¸ ë¡œê·¸
            if idx < 5 or idx >= len(final_collected_data) - 5:
                print(f"  [{idx}]: ì œëª©='{getattr(data, 'title', 'No Title')[:50]}...' ì¶œì²˜='{getattr(data, 'source', 'Unknown')}'")

        print(f"ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ í‚¤ë“¤: {list(full_data_dict.keys())}")
        print(f"ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ í¬ê¸°: {len(full_data_dict)}ê°œ")

        # ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ë¥¼ í”„ë¡ íŠ¸ë¡œ ì „ì†¡
        print(f"\nğŸš€ === í”„ë¡ íŠ¸ì—”ë“œë¡œ FULL_DATA_DICT ì „ì†¡ ===")
        print(f"ì „ì†¡í•  ë°ì´í„° êµ¬ì¡°:")
        print(f"  type: 'full_data_dict'")
        print(f"  data.data_dict í‚¤ë“¤: {list(full_data_dict.keys())}")
        print(f"  data.data_dict í¬ê¸°: {len(full_data_dict)}")

        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (ì²« ë²ˆì§¸ ê²ƒë§Œ)
        if full_data_dict:
            first_key = list(full_data_dict.keys())[0]
            first_item = full_data_dict[first_key]
            print(f"  ìƒ˜í”Œ [{first_key}]: ì œëª©='{first_item['title'][:30]}...' ì¶œì²˜='{first_item['source']}'")

        yield {"type": "full_data_dict", "data": {"data_dict": full_data_dict}}

        # 3. ì„¹ì…˜ë³„ ë°ì´í„° ìƒíƒœ ë¶„ì„ ë° ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„
        # ì¤‘ë³µëœ full_data_dict ìƒì„± ë° ì „ì†¡ ì œê±° (ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨)

        yield self._create_status_event("PROCESSING", "DESIGN_STRUCTURE_START", "ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì¤‘...")

        design = None
        async for result in self.processor.process("design_report_structure", final_collected_data, cumulative_selected_indexes, query, state=state):
            if result.get("type") == "result":
                design = result.get("data")
                break

        if not design or "structure" not in design or not design["structure"]:
            yield {"type": "error", "data": {"message": "ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}}
            return
        
        section_titles = [s.get('section_title', 'ì œëª© ì—†ìŒ') for s in design.get('structure', [])]
        yield self._create_status_event("PROCESSING", "DESIGN_STRUCTURE_COMPLETE", "ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì™„ë£Œ.", details={
            "report_title": design.get("title"),
            "section_titles": section_titles
        })

        # ë³´ê³ ì„œ ì œëª©ì„ ê°€ì¥ ë¨¼ì € ìŠ¤íŠ¸ë¦¬ë°
        yield {"type": "content", "data": {"chunk": f"# {design.get('title', query)}\n\n---\n\n"}}

        # 4. ì„¹ì…˜ë³„ ìƒì„± ë£¨í”„
        for i, section in enumerate(design.get("structure", [])):
            section_title = section.get('section_title', f'ì„¹ì…˜ {i+1}')
            use_contents = section.get("use_contents", [])

            yield self._create_status_event("GENERATING", "GENERATE_SECTION_START", f"'{section_title}' ì„¹ì…˜ ìƒì„± ì¤‘...", details={
                "section_index": i,
                "section_title": section_title,
                "using_indices": use_contents
            })

            # >> ë‹¨ìˆœí™”: section_data_listë§Œ ìƒì„± (ì°¨íŠ¸ìš©)
            section_data_list = []
            for actual_index in use_contents:
                if 0 <= actual_index < len(final_collected_data):
                    section_data_list.append(final_collected_data[actual_index])

            print(f"\nğŸ” === ì„¹ì…˜ '{section_title}' ìƒì„± ë””ë²„ê¹… ===")
            print(f"   ì‚¬ìš©í•  ì‹¤ì œ ì¸ë±ìŠ¤: {use_contents}")
            print(f"   final_collected_data ê¸¸ì´: {len(final_collected_data)}")
            print(f"   full_data_dict í‚¤ë“¤: {list(full_data_dict.keys())}")

            # ì‚¬ìš©ë˜ëŠ” ì¸ë±ìŠ¤ë“¤ì˜ ì‹¤ì œ ë°ì´í„° í™•ì¸
            for idx in use_contents[:3]:  # ì²˜ìŒ 3ê°œë§Œ
                if idx in full_data_dict:
                    print(f"   [{idx}] ì œëª©: '{full_data_dict[idx]['title'][:50]}...'")
                else:
                    print(f"   [âŒ{idx}] ì¸ë±ìŠ¤ê°€ full_data_dictì— ì—†ìŒ!")

            # ì„¹ì…˜ ìƒì„± (ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ì™€ ì‚¬ìš© ì¸ë±ìŠ¤ ì „ë‹¬)
            buffer = ""
            section_content_generated = False
            try:
                async for chunk in self.processor.generate_section_streaming(
                    section, full_data_dict, query, use_contents, state=state
                ):
                    section_content_generated = True
                    buffer += chunk

                    # ì°¨íŠ¸ ìƒì„± ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                    if "[GENERATE_CHART]" in buffer:
                        parts = buffer.split("[GENERATE_CHART]", 1)

                        if parts[0]:
                            yield {"type": "content", "data": {"chunk": parts[0]}}

                        buffer = parts[1]

                        yield self._create_status_event("GENERATING", "GENERATE_CHART_START", f"'{section_title}' ì°¨íŠ¸ ìƒì„± ì¤‘...")

                        # ì°¨íŠ¸ ìƒì„± ê³¼ì •ì˜ ìƒíƒœ ë©”ì‹œì§€ë¥¼ ìœ„í•œ ì½œë°± (ìƒíƒœë§Œ ë°˜í™˜, yield ì—†ìŒ)
                        async def chart_yield_callback(event_data):
                            # ì°¨íŠ¸ ìƒì„± ìƒíƒœ ë¡œê·¸ ì¶œë ¥ (yield ì—†ì´ ìƒíƒœë§Œ ì²˜ë¦¬)
                            print(f"ì°¨íŠ¸ ìƒì„± ìƒíƒœ: {event_data}")
                            return event_data

                        chart_data = None
                        async for result in self.processor.process("create_chart_data", section_data_list, section_title, buffer, "", chart_yield_callback, state=state):
                            if result.get("type") == "chart":
                                chart_data = result.get("data")
                                break

                        if chart_data and "error" not in chart_data:
                            current_chart_index = state.get('chart_counter', 0)
                            chart_placeholder = f"\n\n[CHART-PLACEHOLDER-{current_chart_index}]\n\n"
                            yield {"type": "content", "data": {"chunk": chart_placeholder}}
                            yield {"type": "chart", "data": chart_data}
                            state['chart_counter'] = current_chart_index + 1
                        else:
                            print(f"   ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {chart_data}")
                            yield {"type": "status", "data": {"message": f"'{section_title}' ì°¨íŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤."}}
                            yield {"type": "content", "data": {"chunk": "\n\n*[ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì°¨íŠ¸ í‘œì‹œê°€ ì œí•œë©ë‹ˆë‹¤]*\n\n"}}

                    else:
                        potential_chart_marker = "[GENERATE_CHART]"
                        has_partial_marker = any(potential_chart_marker.startswith(buffer[-i:]) for i in range(1, min(len(buffer)+1, len(potential_chart_marker)+1)) if buffer[-i:])

                        should_flush = (
                            not has_partial_marker and (
                                len(buffer) >= 120 or
                                buffer.endswith(('.', '!', '?', '\n', 'ë‹¤.', 'ìš”.', 'ë‹ˆë‹¤.', 'ìŠµë‹ˆë‹¤.', 'ë©ë‹ˆë‹¤.', 'ìˆìŠµë‹ˆë‹¤.')) or
                                '\n\n' in buffer
                            )
                        )

                        if should_flush:
                            yield {"type": "content", "data": {"chunk": buffer}}
                            buffer = ""

                if buffer.strip():
                    yield {"type": "content", "data": {"chunk": buffer}}

                if not section_content_generated:
                    print(f">> ê²½ê³ : ì„¹ì…˜ '{section_title}' ë‚´ìš© ìƒì„± ì‹¤íŒ¨")
                    yield {"type": "content", "data": {"chunk": f"*'{section_title}' ì„¹ì…˜ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.*\n\n"}}

            except Exception as e:
                print(f">> ì„¹ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                yield {"type": "content", "data": {"chunk": f"*'{section_title}' ì„¹ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}*\n\n"}}

            yield {"type": "content", "data": {"chunk": "\n\n"}}

        # ì›Œí¬í”Œë¡œìš° ì™„ë£Œ í›„ ì¶œì²˜ ì •ë³´ ì„¤ì • (ì‹¤ì œ ì‚¬ìš©ëœ ì¸ë±ìŠ¤ë§Œ)
        # ëª¨ë“  ì„¹ì…˜ì—ì„œ ì‚¬ìš©ëœ ì¸ë±ìŠ¤ë“¤ì„ ìˆ˜ì§‘
        used_indexes = set()
        for section in design.get("structure", []):
            use_contents = section.get("use_contents", [])
            used_indexes.update(use_contents)

        print(f">> ì‹¤ì œ ì‚¬ìš©ëœ ì¸ë±ìŠ¤ë“¤: {sorted(used_indexes)}")
        print(f">> final_collected_data ê¸¸ì´: {len(final_collected_data) if final_collected_data else 0}")
        print(f">> used_indexes ê¸¸ì´: {len(used_indexes)}")

        # sources ì´ë²¤íŠ¸ëŠ” ë” ì´ìƒ ë³´ë‚´ì§€ ì•ŠìŒ (full_data_dictë§Œ ì‚¬ìš©)
        # ëŒ€ì‹  ì‚¬ìš©ëœ ì¸ë±ìŠ¤ ì •ë³´ë§Œ ë¡œê¹…
        if final_collected_data and used_indexes:
            print(f">> ë³´ê³ ì„œì—ì„œ ì‹¤ì œ ì‚¬ìš©ëœ ì¸ë±ìŠ¤ë“¤: {sorted(used_indexes)}")
            print(f">> ì´ {len(used_indexes)}ê°œ ì¶œì²˜ ì‚¬ìš© (ì „ì²´ {len(final_collected_data)}ê°œ ì¤‘)")

        yield {"type": "complete", "data": {
            "message": "ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ"
        }}

    async def _update_use_contents_after_recollection(
    self,
    section_info: Dict,
    all_data: List[SearchResult],
    original_indexes: List[int],
    new_data_indexes: List[int],
    query: str
    ) -> List[int]:
        """ë³´ê°• í›„ í•´ë‹¹ ì„¹ì…˜ì˜ use_contentsë¥¼ LLMì´ ì—…ë°ì´íŠ¸ (ì „ì²´ ë‚´ìš© ê¸°ë°˜)"""

        section_title = section_info.get('section_title', 'ì„¹ì…˜')

        # â­ í•µì‹¬ ê°œì„ : ì „ì²´ ë‚´ìš©ì„ LLMì—ê²Œ ì œê³µ
        data_summary = ""

        # ê¸°ì¡´ ë°ì´í„° (ì „ì²´ ë‚´ìš©)
        data_summary += "=== ê¸°ì¡´ ì„ íƒëœ ë°ì´í„° (ì „ì²´ ë‚´ìš©) ===\n"
        for idx in original_indexes[:3]:  # ì²˜ìŒ 3ê°œë§Œ (ê¸¸ì´ ì œí•œ)
            if 0 <= idx < len(all_data):
                res = all_data[idx]
                content = getattr(res, 'content', '')[:800]  # 800ìë¡œ ì œí•œ
                data_summary += f"""
    [{idx:2d}] [{getattr(res, 'source', 'Unknown')}] {getattr(res, 'title', 'No Title')}
    ë‚´ìš©: {content}{"..." if len(getattr(res, 'content', '')) > 800 else ""}

    """

        # ìƒˆ ë°ì´í„° (ì „ì²´ ë‚´ìš©)
        data_summary += "=== ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„° (ì „ì²´ ë‚´ìš©) ===\n"
        for idx in new_data_indexes:
            if 0 <= idx < len(all_data):
                res = all_data[idx]
                content = getattr(res, 'content', '')[:800]  # 800ìë¡œ ì œí•œ
                data_summary += f"""
    [{idx:2d}] [NEW] [{getattr(res, 'source', 'Unknown')}] {getattr(res, 'title', 'No Title')}
    ë‚´ìš©: {content}{"..." if len(getattr(res, 'content', '')) > 800 else ""}

    """

        update_prompt = f"""
    "{section_title}" ì„¹ì…˜ì„ ìœ„í•´ ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œ ì¶”ê°€ëœ ë°ì´í„°ì˜ **ì „ì²´ ë‚´ìš©ì„ ì½ê³ ** ê°€ì¥ ì í•©í•œ ë°ì´í„°ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

    **ì„¹ì…˜**: "{section_title}"
    **ì „ì²´ ì§ˆë¬¸**: "{query}"

    {data_summary[:8000]}

    **ì„ íƒ ê¸°ì¤€**:
    1. **ê° ë°ì´í„°ì˜ ì „ì²´ ë‚´ìš©ì„ ì½ê³ ** ì„¹ì…˜ ì£¼ì œì™€ì˜ ê´€ë ¨ì„± íŒë‹¨
    2. ì œëª©ë§Œ ë³´ê³  ê²°ì •í•˜ì§€ ë§ê³  **ì‹¤ì œ ë‚´ìš©ì˜ ì§ˆê³¼ ê´€ë ¨ì„±** í™•ì¸
    3. ìƒˆ ë°ì´í„°ëŠ” í•´ë‹¹ ì„¹ì…˜ì„ ìœ„í•´ íŠ¹ë³„íˆ ìˆ˜ì§‘ëœ ê²ƒì´ë¯€ë¡œ ì ê·¹ ê³ ë ¤
    4. ì‹¤ì œë¡œ ìœ ìš©í•œ ì •ë³´ê°€ ë‹´ê¸´ ë°ì´í„°ë§Œ ìµœëŒ€ 8ê°œ ì„ ë³„

    **ì›ë³¸**: {original_indexes}
    **ìƒˆ ë°ì´í„°**: {new_data_indexes}

    JSONìœ¼ë¡œë§Œ ì‘ë‹µ:
    {{
        "updated_use_contents": [0, 2, 5, 8],
        "reasoning": "ê° ë°ì´í„°ë¥¼ ì„ íƒ/ì œì™¸í•œ êµ¬ì²´ì  ì´ìœ  (ë‚´ìš© ê¸°ë°˜)"
    }}
    """

        try:
            response = await self._invoke_with_fallback(update_prompt, self.llm, self.llm_openai_mini)
            result = json.loads(re.search(r'\{.*\}', response.content, re.DOTALL).group())

            updated_indexes = result.get("updated_use_contents", [])
            reasoning = result.get("reasoning", "")

            # ìœ íš¨ì„± ê²€ì¦
            max_index = len(all_data) - 1
            valid_indexes = [idx for idx in updated_indexes if isinstance(idx, int) and 0 <= idx <= max_index]

            print(f"  - use_contents ì—…ë°ì´íŠ¸ ì™„ë£Œ (ì „ì²´ ë‚´ìš© ê¸°ë°˜):")
            print(f"    ìµœì¢… ì„ íƒ: {valid_indexes}")
            print(f"    ì„ íƒ ì´ìœ : {reasoning}")

            return valid_indexes

        except Exception as e:
            print(f"  - use_contents ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            # fallback: ì›ë³¸ + ìƒˆ ë°ì´í„° í•©ì¹˜ê¸° (ìµœëŒ€ 8ê°œ)
            combined = original_indexes + new_data_indexes
            return combined[:8]

