from langchain_core.tools import tool
import re
import sys
import asyncio
import json
import concurrent.futures
import os
from typing import Dict, List, Any, Optional, AsyncGenerator, Tuple
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

from langchain.prompts import PromptTemplate
from langchain import hub
from langchain.agents import AgentExecutor, create_react_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI

from ..models.models import SearchResult
from ...services.search.search_tools import (
    debug_web_search,
    rdb_search,
    vector_db_search,
    graph_db_search,
    scrape_and_extract_content,
)

# ì „ì—­ ThreadPoolExecutor ìƒì„± (ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)
_global_executor = ThreadPoolExecutor(max_workers=8, thread_name_prefix="search_worker")

# ì¶”ê°€: í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
PERSONA_PROMPTS = {}
try:
    with open("agents/prompts/persona_prompts.json", "r", encoding="utf-8") as f:
        PERSONA_PROMPTS = json.load(f)
    print("ProcessorAgent: í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì„±ê³µ.")
except Exception as e:
    print(f"ProcessorAgent: í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ - {e}")


class DataGathererAgent:
    """ë°ì´í„° ìˆ˜ì§‘ ë° ì¿¼ë¦¬ ìµœì í™” ì „ë‹´ Agent"""

    def __init__(self, model: str = "gemini-2.5-flash", temperature: float = 0):
        # Gemini ëª¨ë¸ (ê¸°ë³¸)
        self.llm = ChatGoogleGenerativeAI(model=model, temperature=temperature)

        # OpenAI fallback ëª¨ë¸ë“¤
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if self.openai_api_key:
            self.llm_openai_mini = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=temperature,
                api_key=self.openai_api_key
            )
            self.llm_openai_4o = ChatOpenAI(
                model="gpt-4o",
                temperature=temperature,
                api_key=self.openai_api_key
            )
            print("OpenAI fallback ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.llm_openai_mini = None
            self.llm_openai_4o = None
            print("ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ. Gemini ì˜¤ë¥˜ ì‹œ fallback ë¶ˆê°€")

        # ë„êµ¬ ë§¤í•‘ ì„¤ì • - ì´ë¦„ í†µì¼
        self.tool_mapping = {
            "web_search": self._web_search,
            "vector_db_search": self._vector_db_search,
            "graph_db_search": self._graph_db_search,
            "rdb_search": self._rdb_search,
            "scrape_content": self._scrape_content,
        }

    async def _invoke_with_fallback(self, prompt: str, use_4o: bool = False) -> str:
        """Gemini API ì‹¤íŒ¨ ì‹œ OpenAIë¡œ fallbackí•˜ëŠ” ë©”ì„œë“œ"""
        try:
            # 1ì°¨ ì‹œë„: Gemini
            print("  - Gemini API ì‹œë„ ì¤‘...")
            response = await self.llm.ainvoke(prompt)
            return response.content.strip()
        except Exception as e:
            error_msg = str(e)
            print(f"  - Gemini API ì‹¤íŒ¨: {error_msg}")

            # Rate limit ë˜ëŠ” quota ì˜¤ë¥˜ ì²´í¬
            if any(keyword in error_msg.lower() for keyword in ['429', 'quota', 'rate limit', 'exceeded']):
                print("  - Rate limit ê°ì§€, OpenAIë¡œ fallback ì‹œë„...")

                if self.llm_openai_mini is None:
                    print("  - OpenAI API í‚¤ê°€ ì—†ì–´ fallback ë¶ˆê°€")
                    raise e

                try:
                    # 2ì°¨ ì‹œë„: OpenAI
                    fallback_model = self.llm_openai_4o if use_4o else self.llm_openai_mini
                    model_name = "gpt-4o" if use_4o else "gpt-4o-mini"
                    print(f"  - {model_name} API ì‹œë„ ì¤‘...")
                    response = await fallback_model.ainvoke(prompt)
                    print(f"  - {model_name} API ì„±ê³µ!")
                    return response.content.strip()
                except Exception as openai_error:
                    print(f"  - OpenAI APIë„ ì‹¤íŒ¨: {openai_error}")
                    raise openai_error
            else:
                # Rate limitì´ ì•„ë‹Œ ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ê·¸ëŒ€ë¡œ ë°œìƒ
                raise e

    async def _optimize_query_for_tool(self, query: str, tool: str) -> str:
        """ê° ë„êµ¬ì˜ íŠ¹ì„±ì— ë§ê²Œ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤."""

        # RDBì™€ GraphDBëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì— ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.
        if tool == "rdb_search":
            print(f"  - {tool} ì¿¼ë¦¬ ìµœì í™” ì‹œì‘: '{query}'")
            prompt = f"""
        ë„ˆëŠ” PostgreSQL RDBì— ì§ˆì˜í•  'ìš”ì•½ ê²€ìƒ‰ë¬¸'ì„ ë§Œë“œëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤.
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë‹¤ìŒ ê·œì¹™ìœ¼ë¡œ 1ì¤„ì§œë¦¬ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•´ë¼. (ì¶”ê°€ ì„¤ëª…/ë”°ì˜´í‘œ/ì½”ë“œë¸”ë¡ ê¸ˆì§€)

        [ê·œì¹™]
        1) í¬í•¨ í•­ëª©: ì§€ì—­, í’ˆëª©(ë“¤), ì˜ë„(ê°€ê²©|ì‹œì„¸|ì˜ì–‘|ì¹¼ë¡œë¦¬|ë¹„íƒ€ë¯¼|ë¬´ì—­|ìˆ˜ì¶œ|ìˆ˜ì…|ì‹œì¥í˜„í™© ë“±), ê¸°ê°„.
        2) ì§€ì—­ ì •ê·œí™”:
        - "êµ­ë‚´", "ìš°ë¦¬ë‚˜ë¼", "í•œêµ­" â†’ "ëŒ€í•œë¯¼êµ­".
        - ì§€ì—­ ë¯¸ì–¸ê¸‰ ì‹œ "ëŒ€í•œë¯¼êµ­"ì„ ê¸°ë³¸ìœ¼ë¡œ ë„£ëŠ”ë‹¤.
        3) ê¸°ê°„ ì •ê·œí™”:
        - ì˜¤ëŠ˜/í˜„ì¬ â†’ today
        - ì´ë²ˆì£¼ â†’ this_week
        - ì´ë²ˆë‹¬/ë‹¹ì›”/ìµœê·¼ 1ë‹¬ â†’ this_month ë˜ëŠ” recent(ëª¨í˜¸í•˜ë©´ recent)
        - íŠ¹ì • ì—°ë„/ë‚ ì§œê°€ ìˆìœ¼ë©´ ìˆ«ìë¥¼ ê·¸ëŒ€ë¡œ í¬í•¨ (ì˜ˆ: 2023ë…„ â†’ 2023)
        4) í’ˆëª©ì€ ì§ˆë¬¸ì— ë‚˜ì˜¨ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì ë˜ ë¶ˆí•„ìš”í•œ ì–´ë¯¸/ì¡°ì‚¬ëŠ” ì œê±°(ì˜ˆ: "êµ­ë‚´ì‚° ì‚¬ê³¼" â†’ "ì‚¬ê³¼").
        5) ì˜ë„ëŠ” ì§ˆë¬¸ì—ì„œ ìš”êµ¬í•œ ê²ƒì„ ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´(ì˜ˆ: ê°€ê²©Â·ì‹œì„¸, ì˜ì–‘, ì¹¼ë¡œë¦¬, ë¹„íƒ€ë¯¼C, ìˆ˜ì¶œì•¡, ì„±ì¥ë¥  ë“±).
        6) ì¶œë ¥ í˜•ì‹(ë”± í•œ ì¤„):
        "ì§€ì—­=..., í’ˆëª©=..., ì˜ë„=..., ê¸°ê°„=..."

        [ì˜ˆì‹œ]
        - ì§ˆë¬¸: êµ­ë‚´ ê°ê·¤ì˜ ìµœì‹  ê°€ê²©ê³¼ ì˜ì–‘ì„±ë¶„ ì•Œë ¤ì¤˜
        - ì¶œë ¥: ì§€ì—­=ëŒ€í•œë¯¼êµ­, í’ˆëª©=ê°ê·¤, ì˜ë„=ê°€ê²©Â·ì‹œì„¸Â·ì˜ì–‘, ê¸°ê°„=today

        - ì§ˆë¬¸: ìš°ë¦¬ë‚˜ë¼ íŠ¹ì‚°í’ˆì¸ ì „ë³µì˜ ìœ í†µ êµ¬ì¡°ê°€ ê¶ê¸ˆí•´
        - ì¶œë ¥: ì§€ì—­=ëŒ€í•œë¯¼êµ­, í’ˆëª©=ì „ë³µ, ì˜ë„=ìœ í†µÂ·ì‹œì¥í˜„í™©, ê¸°ê°„=recent

        - ì§ˆë¬¸: ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™©ì„ ì•Œë ¤ì¤˜
        - ì¶œë ¥: ì§€ì—­=ëŒ€í•œë¯¼êµ­, í’ˆëª©=ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ, ì˜ë„=ì‹œì¥í˜„í™©, ê¸°ê°„=recent

        - ì§ˆë¬¸: 2023ë…„ ë§Œë‘ì˜ ì£¼ìš” ìˆ˜ì¶œêµ­ë³„ ìˆ˜ì¶œì•¡ê³¼ ì„±ì¥ë¥ 
        - ì¶œë ¥: ì§€ì—­=ëŒ€í•œë¯¼êµ­, í’ˆëª©=ë§Œë‘, ì˜ë„=ìˆ˜ì¶œì•¡Â·ì„±ì¥ë¥ , ê¸°ê°„=2023

        ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
        ì¶œë ¥:
        """
            try:
                response_content = await self._invoke_with_fallback(prompt)
                optimized_query = response_content.strip()
                print(f"  - ìµœì í™”ëœ í‚¤ì›Œë“œ: '{optimized_query}'")
                return optimized_query
            except Exception as e:
                print(f"  - ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {e}")
                return query

        elif tool == "graph_db_search":
            print(f"  - {tool} ì¿¼ë¦¬ ìµœì í™” ì‹œì‘: '{query}'")

            # ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ê¸°ì¤€: (í’ˆëª©)-[:isFrom]->(Origin), (í’ˆëª©)-[:hasNutrient]->(Nutrient)
            # ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì •ê·œ ë¬¸êµ¬:
            #   - "<í’ˆëª©>ì˜ ì›ì‚°ì§€"            -> isFrom
            #   - "<í’ˆëª©>ì˜ ì˜ì–‘ì†Œ"            -> hasNutrient
            #   - "<ì§€ì—­>ì˜ <í’ˆëª©> ì›ì‚°ì§€"     -> isFrom + region filter
            #   - "(í™œì–´|ì„ ì–´|ëƒ‰ë™|ê±´ì–´) <ìˆ˜ì‚°ë¬¼> ì›ì‚°ì§€" -> isFrom + fishState filter
            prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„, Neo4j ê·¸ë˜í”„ ê²€ìƒ‰ì— ë°”ë¡œ ë„£ì„ ìˆ˜ ìˆëŠ” **ì •ê·œ ì§ˆì˜ ë¬¸êµ¬**ë¡œ ë³€í™˜í•˜ì„¸ìš”.
        ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ:
        - í’ˆëª© ë…¸ë“œ ë¼ë²¨: ë†ì‚°ë¬¼ | ìˆ˜ì‚°ë¬¼ | ì¶•ì‚°ë¬¼  (ê³µí†µ ì†ì„±: product)
        - ì›ì‚°ì§€ ë…¸ë“œ ë¼ë²¨: Origin (ì†ì„±: city, region)
        - ê´€ê³„: (í’ˆëª©)-[:isFrom]->(Origin), (í’ˆëª©)-[:hasNutrient]->(Nutrient)
        - ìˆ˜ì‚°ë¬¼ ìƒíƒœ: fishState âˆˆ {{í™œì–´, ì„ ì–´, ëƒ‰ë™, ê±´ì–´}}

        ê·œì¹™(ë°˜ë“œì‹œ ì¤€ìˆ˜):
        1) ê²°ê³¼ëŠ” **í•œ ì¤„ë‹¹ í•˜ë‚˜ì˜ ì§ˆì˜**ë¡œ ì¶œë ¥í•˜ê³ , ì•„ë˜ 4ê°€ì§€ íŒ¨í„´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
        - "<í’ˆëª©>ì˜ ì›ì‚°ì§€"
        - "<í’ˆëª©>ì˜ ì˜ì–‘ì†Œ"
        - "<ì§€ì—­>ì˜ <í’ˆëª©> ì›ì‚°ì§€"
        - "<ìƒíƒœ> <ìˆ˜ì‚°ë¬¼> ì›ì‚°ì§€"   (ìƒíƒœ=í™œì–´|ì„ ì–´|ëƒ‰ë™|ê±´ì–´ ì¤‘ í•˜ë‚˜)
        2) ì§ˆë¬¸ì— í•´ë‹¹ë˜ì§€ ì•ŠëŠ” íŒ¨í„´ì€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”. ì¶”ì¸¡ ê¸ˆì§€.
        3) ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬/ì„¤ëª…/ë”°ì˜´í‘œ/ë²ˆí˜¸/Bullet ê¸ˆì§€. í…ìŠ¤íŠ¸ë§Œ.
        4) í’ˆëª©, ì§€ì—­, ìƒíƒœëŠ” ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ **ê·¸ëŒ€ë¡œ ë°œì·Œ**í•˜ì„¸ìš”(ë™ì˜ì–´ ì¹˜í™˜ ê¸ˆì§€).
        5) ê²°ê³¼ê°€ ì—†ìœ¼ë©´ **ë¹ˆ ë¬¸ìì—´**ë§Œ ë°˜í™˜.

        ì˜ˆì‹œ:
        - ì§ˆë¬¸: "ì‚¬ê³¼ ì–´ë””ì„œ ë‚˜ì™€?"  ->  ì‚¬ê³¼ì˜ ì›ì‚°ì§€
        - ì§ˆë¬¸: "ì˜¤ë Œì§€ ì˜ì–‘ ì„±ë¶„ ì•Œë ¤ì¤˜" -> ì˜¤ë Œì§€ì˜ ì˜ì–‘ì†Œ
        - ì§ˆë¬¸: "ê²½ìƒë¶ë„ ì‚¬ê³¼ ì‚°ì§€" -> ê²½ìƒë¶ë„ì˜ ì‚¬ê³¼ ì›ì‚°ì§€
        - ì§ˆë¬¸: "í™œì–´ ë¬¸ì–´ ì‚°ì§€" -> í™œì–´ ë¬¸ì–´ ì›ì‚°ì§€

        ì§ˆë¬¸: "{query}"
        ì¶œë ¥:
        """.strip()

            try:
                response_content = await self._invoke_with_fallback(prompt)
                # íŒŒì‹±: ì¤„ ë‹¨ìœ„ë¡œ ì •ë¦¬, í—ˆìš© íŒ¨í„´ë§Œ í†µê³¼
                allowed_prefixes = ("í™œì–´ ", "ì„ ì–´ ", "ëƒ‰ë™ ", "ê±´ì–´ ")
                def _is_allowed(line: str) -> bool:
                    if not line: return False
                    # íŒ¨í„´ 1/2: "<í’ˆëª©>ì˜ (ì›ì‚°ì§€|ì˜ì–‘ì†Œ)"
                    if "ì˜ ì›ì‚°ì§€" in line or "ì˜ ì˜ì–‘ì†Œ" in line:
                        return True
                    # íŒ¨í„´ 3: "<ì§€ì—­>ì˜ <í’ˆëª©> ì›ì‚°ì§€"
                    if line.endswith(" ì›ì‚°ì§€") and "ì˜ " in line and not any(line.startswith(p) for p in allowed_prefixes):
                        return True
                    # íŒ¨í„´ 4: "<ìƒíƒœ> <ìˆ˜ì‚°ë¬¼> ì›ì‚°ì§€"
                    if line.endswith(" ì›ì‚°ì§€") and any(line.startswith(p) for p in allowed_prefixes):
                        return True
                    return False

                lines = [l.strip().lstrip("-â€¢").strip().strip('"').strip("'") for l in response_content.splitlines()]
                lines = [l for l in lines if _is_allowed(l)]
                optimized_query = "\n".join(dict.fromkeys(lines))  # ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€

                print(f"  - ìµœì í™”ëœ í‚¤ì›Œë“œ(ì •ê·œ ì§ˆì˜):\n{optimized_query or '(empty)'}")
                return optimized_query if optimized_query else query  # ë¹„ë©´ ì›ë³¸ ì§ˆë¬¸ ì „ë‹¬

            except Exception as e:
                print(f"  - ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {e}")
                return query

        # Vector DBëŠ” êµ¬ì²´ì ì¸ ì •ë³´ ê²€ìƒ‰ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜
        elif tool == "vector_db_search":
            print(f"  - {tool} ì¿¼ë¦¬ ìµœì í™” ì‹œì‘ (ì •ë³´ ê²€ìƒ‰ ì§ˆë¬¸ ë³€í™˜): '{query}'")
            prompt = f"""
ë‹¤ìŒ ìš”ì²­ì„ Vector DBì—ì„œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” **ë‹¨ì¼ ì§ˆë¬¸**ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

**ì¤‘ìš” ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)**:
1. **ì˜¤ì§ í•˜ë‚˜ì˜ ê°„ë‹¨í•œ ì§ˆë¬¸ë§Œ ìƒì„±** - ì ˆëŒ€ ì—¬ëŸ¬ ì§ˆë¬¸ ìƒì„± ê¸ˆì§€
2. **ë²ˆí˜¸ ë§¤ê¸°ê¸° ì ˆëŒ€ ê¸ˆì§€** (1., 2., 3. ë“± ì‚¬ìš© ê¸ˆì§€)
3. **ëª©ë¡ì´ë‚˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ê¸ˆì§€**
4. **"ì›ë³¸ ìš”ì²­:", "ë³€í™˜ëœ ì§ˆë¬¸:" ë“± ë¶€ê°€ ì„¤ëª… ê¸ˆì§€**
5. **ì§ˆë¬¸ í•˜ë‚˜ë§Œ ê°„ê²°í•˜ê²Œ ì¶œë ¥**

ë³€í™˜ ê·œì¹™:
- ì¶”ìƒì  ì§ˆë¬¸ ê¸ˆì§€: "ì¸ì‚¬ì´íŠ¸", "ì „ë§", "íŠ¸ë Œë“œ" ë“± â†’ êµ¬ì²´ì  ìˆ˜ì¹˜ ìš”ì²­ìœ¼ë¡œ ë³€í™˜
- ì§€ì—­ ì •ë³´ ëª…í™•í™”: "êµ­ë‚´"â†’"ëŒ€í•œë¯¼êµ­", "ìš°ë¦¬ë‚˜ë¼"â†’"ëŒ€í•œë¯¼êµ­", "í•œêµ­"â†’"ëŒ€í•œë¯¼êµ­"
- ì‹œê°„ í‘œí˜„ êµ¬ì²´í™”: "ìµœê·¼"â†’"2024ë…„, 2025ë…„", "ìš”ì¦˜"â†’"2024ë…„, 2025ë…„", "í˜„ì¬"â†’"2025ë…„"
- êµ¬ì²´ì  ì •ë³´ ìš”ì²­: "ë§¤ì¶œì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?", "ì ìœ ìœ¨ì€ ëª‡ í¼ì„¼íŠ¸ì¸ê°€ìš”?" í˜•íƒœ

ë³€í™˜ ì˜ˆì‹œ:
ì…ë ¥: "êµ­ë‚´ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ì˜ ìµœê·¼ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤"
ì¶œë ¥: ëŒ€í•œë¯¼êµ­ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ì˜ 2024ë…„ ë§¤ì¶œì•¡ê³¼ ì£¼ìš” ê¸°ì—… ì ìœ ìœ¨ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?

ì…ë ¥: "ìš°ë¦¬ë‚˜ë¼ ì‹ìì¬ ì‹œì¥ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
ì¶œë ¥: 2024ë…„ ëŒ€í•œë¯¼êµ­ ì‹ìì¬ ì‹œì¥ ê·œëª¨ì™€ ì£¼ìš” ìœ í†µì—…ì²´ë³„ ë§¤ì¶œ í˜„í™©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?

**ì›ë³¸ ìš”ì²­**: "{query}"

**ë³€í™˜ëœ ë‹¨ì¼ ì§ˆë¬¸** (ì§ˆë¬¸ í•˜ë‚˜ë§Œ ì¶œë ¥):
"""
            try:
                raw_query = await self._invoke_with_fallback(prompt)

                # [ì¶”ê°€ë¨] ê°•ë ¥í•œ í›„ì²˜ë¦¬ë¡œ ë‹¨ì¼ ì§ˆë¬¸ë§Œ ì¶”ì¶œ
                optimized_query = self._extract_single_question(raw_query)

                print(f"  - ìµœì í™”ëœ ì§ˆë¬¸: '{optimized_query}'")
                return optimized_query
            except Exception as e:
                print(f"  - ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {e}")
                return query

        # Web SearchëŠ” ë§¥ë½ ì •ë³´ë¥¼ í¬í•¨í•œ ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ìµœì í™”
        elif tool == "web_search":
            print(f"  - {tool} ì¿¼ë¦¬ ìµœì í™” ì‹œì‘ (ë§¥ë½ ê°•í™”): '{query}'")
            prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ì›¹ ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
ê²€ìƒ‰ íš¨ê³¼ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì¤‘ìš”í•œ ë§¥ë½ ì •ë³´(êµ­ê°€, ì—°ë„, ëŒ€ìƒ ë“±)ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

ìµœì í™” ê·œì¹™:
1. ì§€ì—­ ì •ë³´ ëª…í™•í™” ë° ê¸°ë³¸ê°’ ì„¤ì •:
   - "êµ­ë‚´" â†’ "ëŒ€í•œë¯¼êµ­"
   - "ìš°ë¦¬ë‚˜ë¼" â†’ "ëŒ€í•œë¯¼êµ­"
   - "í•œêµ­" â†’ "ëŒ€í•œë¯¼êµ­"
   - ì§€ì—­ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ â†’ "ëŒ€í•œë¯¼êµ­" ìë™ ì¶”ê°€
2. êµ¬ì²´ì ì¸ ì—°ë„ ëª…ì‹œ:
   - "ìµœê·¼" â†’ "2024ë…„ 2025ë…„"
   - "ìš”ì¦˜" â†’ "2024ë…„ 2025ë…„"
   - "í˜„ì¬" â†’ "2025ë…„"
   - "ì‘ë…„" â†’ "2024ë…„"
3. êµ¬ì²´ì ì¸ ë¶„ì•¼ë‚˜ ëŒ€ìƒ ëª…ì‹œ
4. ê²€ìƒ‰ ì˜ë„ì— ë§ëŠ” í‚¤ì›Œë“œ ì¡°í•©

ì˜ˆì‹œ:
- ì›ë³¸: "êµ­ë‚´ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™©ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤"
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™© íŠ¸ë Œë“œ"

- ì›ë³¸: "ìš°ë¦¬ë‚˜ë¼ MZì„¸ëŒ€ ì†Œë¹„ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤"
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ MZì„¸ëŒ€ ì†Œë¹„ íŠ¸ë Œë“œ íŒ¨í„´"

- ì›ë³¸: "ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™©ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤" (ì§€ì—­ ì–¸ê¸‰ ì—†ìŒ)
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™© íŠ¸ë Œë“œ"

- ì›ë³¸: "í•œêµ­ì˜ ìœ ë§í•œ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ë¶„ì•¼ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤"
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ìœ ë§ ë¶„ì•¼ ì‹œì¥ ì „ë§"

- ì›ë³¸: "ìµœê·¼ ì‹ìì¬ ì‹œì¥ íŠ¸ë Œë“œë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤"
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ì‹ìì¬ ì‹œì¥ íŠ¸ë Œë“œ ë™í–¥ ë¶„ì„"

ì›ë³¸ ì§ˆë¬¸: "{query}"
ìµœì í™”ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
"""
            try:
                optimized_query = await self._invoke_with_fallback(prompt)
                print(f"  - ìµœì í™”ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ: '{optimized_query}'")
                return optimized_query
            except Exception as e:
                print(f"  - ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {e}")
                return query

        # ê¸°íƒ€ ë„êµ¬ëŠ” ì›ë³¸ ì¿¼ë¦¬ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        return query

    def _extract_single_question(self, raw_response: str) -> str:
        """LLM ì‘ë‹µì—ì„œ ë‹¨ì¼ ì§ˆë¬¸ë§Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ ë©”ì„œë“œ"""
        lines = raw_response.strip().split('\n')

        # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if not line:
                continue
            # ë²ˆí˜¸ ë§¤ê¸°ê¸°ë‚˜ ë¶€ê°€ ì„¤ëª… ì œê±°
            if line.startswith(('1.', '2.', '3.', '4.', '5.', '6.', '-', '*')):
                continue
            if 'ì›ë³¸' in line or 'ë³€í™˜' in line or 'ì§ˆë¬¸:' in line or 'ì¶œë ¥:' in line:
                continue
            if '**' in line:  # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
                continue
            cleaned_lines.append(line)

        # ì²« ë²ˆì§¸ ì§ˆë¬¸ ë¬¸ì¥ë§Œ ë°˜í™˜
        for line in cleaned_lines:
            if line.endswith('?') or line.endswith('ìš”') or line.endswith('ê¹Œ'):
                return line

        # ì ì ˆí•œ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìœ íš¨í•œ ë¼ì¸ ë°˜í™˜
        if cleaned_lines:
            return cleaned_lines[0]

        # ëª¨ë“  ì²˜ë¦¬ê°€ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ì‘ë‹µ ë°˜í™˜
        return raw_response.strip()


    async def execute(self, tool: str, inputs: Dict[str, Any]) -> Tuple[List[SearchResult], str]:
        """ë‹¨ì¼ ë„êµ¬ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©°, ì‹¤í–‰ ì „ ì¿¼ë¦¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤."""
        if tool not in self.tool_mapping:
            print(f"- ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool}")
            return []

        original_query = inputs.get("query", "")
        # [ìˆ˜ì •ë¨] ì‹¤ì œ ë„êµ¬ ì‹¤í–‰ ì „, ì¿¼ë¦¬ ìµœì í™” ë‹¨ê³„ ì¶”ê°€
        optimized_query = await self._optimize_query_for_tool(original_query, tool)

        # ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ìƒˆë¡œìš´ inputs ë”•ì…”ë„ˆë¦¬ ìƒì„±
        optimized_inputs = inputs.copy()
        optimized_inputs["query"] = optimized_query

        try:
            print(f"\n>> DataGatherer: '{tool}' ë„êµ¬ ì‹¤í–‰ (ì¿¼ë¦¬: '{optimized_query}')")
            result = await self.tool_mapping[tool](**optimized_inputs)
            return result, optimized_query
        except Exception as e:
            print(f"- {tool} ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return [], optimized_query


    async def execute_parallel(self, tasks: List[Dict[str, Any]]) -> Dict[str, List[SearchResult]]:
        """ì—¬ëŸ¬ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print(f"\n>> DataGatherer: {len(tasks)}ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘")

        # ê° ì‘ì—…ì— ëŒ€í•´ execute ì½”ë£¨í‹´ì„ ìƒì„±í•©ë‹ˆë‹¤. execute ë‚´ë¶€ì—ì„œ ì¿¼ë¦¬ ìµœì í™”ê°€ ìë™ìœ¼ë¡œ ì¼ì–´ë‚©ë‹ˆë‹¤.
        coroutines = [self.execute(task.get("tool"), task.get("inputs", {})) for task in tasks]

        # asyncio.gatherë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°›ìŠµë‹ˆë‹¤.
        results = await asyncio.gather(*coroutines, return_exceptions=True)



        organized_results = {}
        for i, task in enumerate(tasks):
            tool_name = task.get("tool", f"unknown_tool_{i}")
            result = results[i]

            # ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
            if isinstance(result, Exception):
                print(f"  - {tool_name} ë³‘ë ¬ ì‹¤í–‰ ì˜¤ë¥˜: {result}")
                organized_results[f"{tool_name}_{i}"] = []
            else:
                print(f"  - {tool_name} ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ: {len(result)}ê°œ ê²°ê³¼")
                print(f"  - {tool_name} ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼: {result[:3]}...")  # ì²˜ìŒ 3ê°œ ê²°ê³¼ë§Œ ì¶œë ¥
                search_results, optimized_query = result  # íŠœí”Œ ì–¸íŒ¨í‚¹
                organized_results[f"{tool_name}_{i}"] = search_results

        return organized_results

    async def execute_parallel_streaming(self, tasks: List[Dict[str, Any]], state: Dict[str, Any] = None):
        """ì—¬ëŸ¬ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ë˜, ê° ì‘ì—…ì´ ì™„ë£Œë  ë•Œë§ˆë‹¤ ì‹¤ì‹œê°„ìœ¼ë¡œ yieldí•©ë‹ˆë‹¤."""
        print(f"\n>> DataGatherer: {len(tasks)}ê°œ ì‘ì—… ìŠ¤íŠ¸ë¦¬ë° ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘")

        # ë””ë²„ê¹…
        import pprint
        print("\n-- Tasks to be executed --")
        pprint.pprint(tasks, width=100, depth=2)
        print("\n-- Tasks to be executed --")

        # ê° íƒœìŠ¤í¬ì— ì¸ë±ìŠ¤ë¥¼ í• ë‹¹í•˜ì—¬ ìˆœì„œë¥¼ ì¶”ì 
        async def execute_with_callback(task_index: int, task: Dict[str, Any]):
            tool_name = task.get("tool", f"unknown_tool_{task_index}")
            inputs = task.get("inputs", {})
            query = inputs.get("query", "")

            try:
                print(f"  - {tool_name} ì‹œì‘: {query}")
                result, optimized_query = await self.execute(tool_name, inputs)
                print(f"  - {tool_name} ì™„ë£Œ: {len(result)}ê°œ ê²°ê³¼")

                # í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                formatted_results = []
                for search_result in result:
                    result_dict = search_result.model_dump()
                    formatted_result = {
                        "title": result_dict.get("title", "ì œëª© ì—†ìŒ"),
                        "content": result_dict.get("content", "content ì—†ìŒ"),
                        "url": result_dict.get("url", "url ì—†ìŒ"),
                        "source": result_dict.get("source", tool_name),
                        "score": result_dict.get("score", 0.0),
                    }
                    formatted_results.append(formatted_result)

                    print(f"  - {tool_name} ê²°ê³¼ í¬ë§· ì™„ë£Œ: {formatted_result}")

                return {
                    "step": task_index + 1,
                    "tool_name": tool_name,
                    "query": optimized_query,
                    "results": formatted_results,
                    "original_results": result  # ì›ë³¸ SearchResult ê°ì²´ë“¤ë„ ë³´ì¡´
                }

            except Exception as e:
                print(f"  - {tool_name} ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                return {
                    "step": task_index + 1,
                    "tool_name": tool_name,
                    "query": optimized_query,
                    "results": [],
                    "error": str(e),
                    "original_results": []
                }

        # ëª¨ë“  ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì‹œì‘í•˜ê³ , ì™„ë£Œë˜ëŠ” ëŒ€ë¡œ yield
        tasks_coroutines = [execute_with_callback(i, task) for i, task in enumerate(tasks)]

        # asyncio.as_completedë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ì²˜ë¦¬
        collected_data = []

        for coro in asyncio.as_completed(tasks_coroutines):
            result = await coro
            collected_data.extend(result.get("original_results", []))

            # ê°œë³„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¦‰ì‹œ yield
            yield {
                "type": "search_results",
                "data": {
                    "step": result["step"],
                    "tool_name": result["tool_name"],
                    "query": result["query"],
                    "results": result["results"],
                    "message_id": state.get("message_id") if state else None
                }
            }

        # ëª¨ë“  ê²€ìƒ‰ì´ ì™„ë£Œëœ í›„ ì „ì²´ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë§ˆì§€ë§‰ì— yield
        yield {
            "type": "collection_complete",
            "data": {
                "total_results": len(collected_data),
                "collected_data": collected_data
            }
        }


    async def _web_search(self, query: str, **kwargs) -> List[SearchResult]:
        """ì›¹ ê²€ìƒ‰ ì‹¤í–‰ - ì•ˆì •ì„± ê°•í™”"""
        try:
            # ìµœì í™”ëœ ì¿¼ë¦¬ ì‚¬ìš© (ì´ë¯¸ _optimize_query_for_toolì—ì„œ ì²˜ë¦¬ë¨)
            print(f"  - ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ì¿¼ë¦¬: {query}")

            # ì „ì—­ ThreadPoolExecutor ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
            loop = asyncio.get_event_loop()
            result_text = await loop.run_in_executor(
                _global_executor,  # ì „ì—­ executor ì‚¬ìš©
                debug_web_search,
                query
            )

            # ê²°ê³¼ê°€ ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
            search_results = []
            if result_text and isinstance(result_text, str):
                # ê°„ë‹¨í•œ íŒŒì‹±ìœ¼ë¡œ SearchResult ê°ì²´ ìƒì„±
                lines = result_text.split('\n')
                current_result = {}

                for line in lines:
                    line = line.strip()
                    if line.startswith(('1.', '2.', '3.', '4.', '5.')):
                        # ì´ì „ ê²°ê³¼ ì €ì¥
                        if current_result:
                            search_result = SearchResult(
                                source="web_search",
                                content=current_result.get("snippet", ""),
                                search_query=query,
                                title=current_result.get("title", "ì›¹ ê²€ìƒ‰ ê²°ê³¼"),
                                url=current_result.get("link"),
                                score=0.9,  # ì›¹ê²€ìƒ‰ ê²°ê³¼ëŠ” ë†’ì€ ì ìˆ˜
                                timestamp=datetime.now().isoformat(),
                                document_type="web",
                                metadata={"optimized_query": query, **current_result},
                                source_url=current_result.get("link", "ì›¹ ê²€ìƒ‰ ê²°ê³¼")
                            )
                            search_results.append(search_result)

                        # ìƒˆ ê²°ê³¼ ì‹œì‘
                        current_result = {"title": line[3:].strip()}  # ë²ˆí˜¸ ì œê±°
                    elif line.startswith("ì¶œì²˜ ë§í¬:"):
                        current_result["link"] = line[7:].strip()  # "ì¶œì²˜ ë§í¬:" ì œê±°
                    elif line.startswith("ìš”ì•½:"):
                        current_result["snippet"] = line[3:].strip()

                # ë§ˆì§€ë§‰ ê²°ê³¼ ì €ì¥
                if current_result:
                    search_result = SearchResult(
                        source="web_search",
                        content=current_result.get("snippet", ""),
                        search_query=query,
                        title=current_result.get("title", "ì›¹ ê²€ìƒ‰ ê²°ê³¼"),
                        url=current_result.get("link"),
                        score=0.9,  # ì›¹ê²€ìƒ‰ ê²°ê³¼ëŠ” ë†’ì€ ì ìˆ˜
                        timestamp=datetime.now().isoformat(),
                        document_type="web",
                        metadata={
                            "optimized_query": query,
                            "link": current_result.get("link"),  # ì¶œì²˜ ë§í¬ í¬í•¨
                            **current_result
                        },
                        source_url=current_result.get("link", "ì›¹ ê²€ìƒ‰ ê²°ê³¼")
                    )
                    search_results.append(search_result)

            print(f"  - ì›¹ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            return search_results[:5]  # ìƒìœ„ 5ê°œ ê²°ê³¼ë§Œ

        except concurrent.futures.TimeoutError:
            print(f"ì›¹ ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
            return []
        except Exception as e:
            print(f"ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def _vector_db_search(self, query: str, **kwargs) -> List[SearchResult]:
        """Vector DB ê²€ìƒ‰ ì‹¤í–‰ - ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”"""
        try:
            print(f">> Vector DB ê²€ìƒ‰ ì‹œì‘: {query}")
            
            # ì „ì—­ ThreadPoolExecutor ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
            loop = asyncio.get_event_loop()
            results = await loop.run_in_executor(
                _global_executor,  # ì „ì—­ executor ì‚¬ìš©
                vector_db_search,
                query
            )

            search_results = []
            for result in results:
                if isinstance(result, dict):
                    # ìƒˆë¡œìš´ doc_linkì™€ page_number í•„ë“œ ì‚¬ìš©
                    doc_link = result.get("source_url", "")
                    page_number = result.get("page_number", [])
                    # ë¬¸ì„œ ì œëª© ì¶”ì¶œ
                    doc_title = result.get("title", "")

                    # ì œëª©ì— í˜ì´ì§€ ë²ˆí˜¸ ì¶”ê°€
                    full_title = f"{doc_title}, ({', '.join(map(str, page_number))})".strip()
                    score = result.get("score", 5.2)

                    search_results.append(SearchResult(
                        source="_search",
                        content=result.get("content", ""),
                        search_query=query,
                        title=full_title,
                        document_type="database",
                        score=score,
                        url=doc_link,  # ìƒˆ í•„ë“œ ì¶”ê°€
                    ))


            print(f"  - Vector DB ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            return search_results[:5]

        # except concurrent.futures.TimeoutError:
        #     print(f"Vector DB ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
        #     return []
        except Exception as e:
            print(f"Vector DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    async def _graph_db_search(self, query: str, **kwargs) -> List[SearchResult]:
        """Graph DB ê²€ìƒ‰ ì‹¤í–‰ - í¬ë§· ë¶ˆì¼ì¹˜ ë°©ì§€ ë° íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬"""
        print(f"  - Graph DB ê²€ìƒ‰ ì‹œì‘: {query}")
        import concurrent.futures

        try:
            # graph_db_searchê°€ ë™ê¸° í•¨ìˆ˜ë¼ë©´
            loop = asyncio.get_running_loop()
            raw_results = await loop.run_in_executor(None, graph_db_search, query)
            # ë§Œì•½ langchain Toolì¼ ê²½ìš°:
            # with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            #     raw_results = executor.submit(graph_db_search.invoke, {"query": query}).result(timeout=20)

            search_results: List[SearchResult] = []

            if isinstance(raw_results, list):
                # list of dict or list of str
                for res in raw_results[:5]:
                    if isinstance(res, dict):
                        # Graph DB ê²°ê³¼ì˜ ì˜ë¯¸ìˆëŠ” ì œëª© ìƒì„±
                        title_candidates = [
                            res.get("title"),
                            res.get("entity"),
                            res.get("product"),
                            res.get("name"),
                            res.get("í’ˆëª©ëª…"),
                            res.get("ì›ì‚°ì§€"),
                            res.get("ì˜ì–‘ì†Œëª…")
                        ]
                        title = next((t for t in title_candidates if t), "ê·¸ë˜í”„ ì •ë³´")

                        # ê´€ê³„í˜• ë°ì´í„°ì˜ ì˜ë¯¸ìˆëŠ” ë‚´ìš© ìƒì„±
                        content_parts = []
                        relationship_info = []

                        # ê´€ê³„ ì •ë³´ ì¶”ì¶œ
                        for key, value in res.items():
                            if "ê´€ê³„" in key or "ì—°ê²°" in key or key.endswith("_ê´€ê³„"):
                                relationship_info.append(f"ğŸ”— {key}: {value}")
                            elif key not in ['title', 'content', 'entity', 'product'] and value:
                                content_parts.append(f"â€¢ {key}: {value}")

                        if relationship_info:
                            content_parts = relationship_info + content_parts

                        content = res.get("content") or "\n".join(content_parts[:8]) or json.dumps(res, ensure_ascii=False, indent=2)
                        score = res.get("confidence") or res.get("score") or 0.8
                    else:
                        title = f"ê·¸ë˜í”„ ê´€ê³„ ì •ë³´"
                        content = str(res)
                        score = 0.8

                    search_results.append(
                        SearchResult(
                            source="graph_db",
                            content=content,
                            search_query=query,
                            title=title,
                            score=score,
                            document_type="graph",
                            url=""  # ë¹ˆ ë¬¸ìì—´ë¡œ í†µì¼ (None ì“°ë©´ í›„ë‹¨ì—ì„œ ê¹¨ì§€ëŠ” ê²½ìš° ìˆìŒ)
                        )
                    )
            elif isinstance(raw_results, dict):
                # ë‹¨ì¼ ê·¸ë˜í”„ ê²°ê³¼ì˜ ì˜ë¯¸ìˆëŠ” ì œëª© ìƒì„±
                title_candidates = [
                    raw_results.get("title"),
                    raw_results.get("entity"),
                    raw_results.get("product"),
                    raw_results.get("name"),
                    raw_results.get("í’ˆëª©ëª…")
                ]
                title = next((t for t in title_candidates if t), "ê·¸ë˜í”„ ê´€ê³„ ì •ë³´")

                # êµ¬ì¡°í™”ëœ ë‚´ìš© ìƒì„±
                content_parts = []
                for key, value in raw_results.items():
                    if key not in ['title', 'content', 'entity', 'product'] and value:
                        if "ê´€ê³„" in key or "ì—°ê²°" in key:
                            content_parts.append(f"ğŸ”— {key}: {value}")
                        else:
                            content_parts.append(f"â€¢ {key}: {value}")

                content = raw_results.get("content") or "\n".join(content_parts[:8]) or json.dumps(raw_results, ensure_ascii=False, indent=2)
                score = raw_results.get("confidence") or raw_results.get("score") or 0.8
                search_results.append(
                    SearchResult(
                        source="graph_db",
                        content=content,
                        search_query=query,
                        title=title,
                        score=score,
                        document_type="graph",
                        url=""
                    )
                )
            else:
                # ë¬¸ìì—´ summary ê°™ì€ ê²½ìš°
                content = str(raw_results)
                title = "ê·¸ë˜í”„ ê²€ìƒ‰ ìš”ì•½"
                search_results.append(
                    SearchResult(
                        source="graph_db",
                        content=content,
                        search_query=query,
                        title=title,
                        score=0.6,
                        document_type="graph",
                        url=""
                    )
                )

            print(f"  - Graph DB ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            return search_results

        except concurrent.futures.TimeoutError:
            print(f"Graph DB ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
            return []
        except Exception as e:
            print(f"Graph DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def _rdb_search(self, query: str, **kwargs) -> List[SearchResult]:
        """RDB ê²€ìƒ‰ ì‹¤í–‰ - ë°˜í™˜ í‘œì¤€í™”"""
        try:
            loop = asyncio.get_running_loop()
            result_text = await loop.run_in_executor(None, rdb_search, query)

            # rdb_searchëŠ” ë¬¸ìì—´ì„ ë°˜í™˜í•˜ë¯€ë¡œ, ì´ë¥¼ ë‹¨ì¼ SearchResultë¡œ ë³€í™˜
            if isinstance(result_text, str) and result_text.strip():
                # "PostgreSQL ê²€ìƒ‰ ê²°ê³¼: "ë¡œ ì‹œì‘í•˜ëŠ”ì§€ ì²´í¬
                if "PostgreSQL ê²€ìƒ‰ ê²°ê³¼:" in result_text and "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in result_text:
                    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
                    print(f"  - RDBì—ì„œ '{query}' ê´€ë ¨ ë°ì´í„° ì—†ìŒ")
                    return []

                search_result = SearchResult(
                    source="rdb_search",
                    content=result_text,
                    search_query=query,
                    title="PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼",
                    url="",
                    score=0.9,
                    document_type="database",
                    metadata={"raw_result": result_text}
                )
                print(f"  - rdb_search ë˜í¼ ë°˜í™˜: 1ê°œ (í…ìŠ¤íŠ¸ ê²°ê³¼)")
                return [search_result]
            else:
                print(f"  - RDB ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                return []


        except Exception as e:
            print(f"RDB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def _scrape_content(self, url: str, query: str = "", **kwargs) -> List[SearchResult]:
        """ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰"""
        try:
            content = await asyncio.get_event_loop().run_in_executor(
                None, scrape_and_extract_content, url, query
            )

            if content:
                search_result = SearchResult(
                    source="scrape_content",
                    content=content,
                    search_query=query,
                    title=f"ìŠ¤í¬ë˜í•‘ëœ ì½˜í…ì¸ : {url}",
                    url=url,
                    relevance_score=0.9,
                    timestamp=datetime.now().isoformat(),
                    document_type="web",
                    metadata={"scraped_url": url}
                )
                return [search_result]

            return []
        except Exception as e:
            print(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            return []



class ProcessorAgent:
    """ë°ì´í„° ê°€ê³µ ë° ìƒì„± ì „ë‹´ Agent (ReAct ì œê±°, ìˆœì°¨ ìƒì„± ì§€ì›)"""

    def __init__(self, model_pro: str = "gemini-2.5-pro", model_flash: str = "gemini-2.5-flash", temperature: float = 0.3):
        # ë³´ê³ ì„œ ìµœì¢… ìƒì„±ì„ ìœ„í•œ ê³ í’ˆì§ˆ ëª¨ë¸ (Gemini)
        self.llm_pro = ChatGoogleGenerativeAI(model=model_pro, temperature=temperature)
        # êµ¬ì¡° ì„¤ê³„, ìš”ì•½ ë“± ë¹ ë¥¸ ì‘ì—…ì— ì‚¬ìš©í•  ê²½ëŸ‰ ëª¨ë¸ (Gemini)
        self.llm_flash = ChatGoogleGenerativeAI(model=model_flash, temperature=0.1)

        # OpenAI fallback ëª¨ë¸ë“¤
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if self.openai_api_key:
            self.llm_openai_mini = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0.1,
                api_key=self.openai_api_key
            )
            self.llm_openai_4o = ChatOpenAI(
                model="gpt-4o",
                temperature=temperature,
                api_key=self.openai_api_key
            )
            print("ProcessorAgent: OpenAI fallback ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.llm_openai_mini = None
            self.llm_openai_4o = None
            print("ProcessorAgent: ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")

        self.personas = PERSONA_PROMPTS

        # Orchestratorê°€ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ì‘ì—… ëª©ë¡ ì •ì˜
        self.processor_mapping = {
            "design_report_structure": self._design_report_structure,
            "create_chart_data": self._create_charts,
        }

    async def _invoke_with_fallback(self, prompt, primary_model, fallback_model):
        """
        Gemini API rate limit ì‹œ OpenAIë¡œ fallback ì²˜ë¦¬
        """
        try:
            result = await primary_model.ainvoke(prompt)
            return result
        except Exception as e:
            error_str = str(e).lower()
            rate_limit_indicators = ['429', 'quota', 'rate limit', 'exceeded', 'resource_exhausted']

            if any(indicator in error_str for indicator in rate_limit_indicators):
                print(f"ProcessorAgent: Gemini API rate limit ê°ì§€, OpenAIë¡œ fallback ì‹œë„: {e}")
                if fallback_model:
                    try:
                        result = await fallback_model.ainvoke(prompt)
                        print("ProcessorAgent: OpenAI fallback ì„±ê³µ")
                        return result
                    except Exception as fallback_error:
                        print(f"ProcessorAgent: OpenAI fallbackë„ ì‹¤íŒ¨: {fallback_error}")
                        raise fallback_error
                else:
                    print("ProcessorAgent: OpenAI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                    raise e
            else:
                raise e

    async def _astream_with_fallback(self, prompt, primary_model, fallback_model):
        """
        ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ Gemini API rate limit ì‹œ OpenAIë¡œ fallback ì²˜ë¦¬
        """
        primary_chunks_received = 0
        primary_content_length = 0

        try:
            print(f"- Primary ëª¨ë¸ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹œë„ ({type(primary_model).__name__})")
            async for chunk in primary_model.astream(prompt):
                primary_chunks_received += 1
                if hasattr(chunk, 'content') and chunk.content:
                    primary_content_length += len(chunk.content)
                yield chunk

            print(f"- Primary ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: {primary_chunks_received}ê°œ ì²­í¬, {primary_content_length} ë¬¸ì")

            # ì²­í¬ë¥¼ ë°›ì•˜ì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°ë„ ì‹¤íŒ¨ë¡œ ê°„ì£¼
            if primary_chunks_received == 0 or primary_content_length == 0:
                print(f"- Primary ëª¨ë¸ì—ì„œ ìœ íš¨í•œ ë‚´ìš©ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ, fallback ì‹¤í–‰")
                raise Exception("No valid content generated")

        except Exception as e:
            error_str = str(e).lower()
            rate_limit_indicators = ['429', 'quota', 'rate limit', 'exceeded', 'resource_exhausted', 'no valid content', 'no generation chunks']

            if any(indicator in error_str for indicator in rate_limit_indicators) or primary_chunks_received == 0:
                print(f"ProcessorAgent: Gemini API ë¬¸ì œ ê°ì§€ (ì²­í¬:{primary_chunks_received}, ë‚´ìš©:{primary_content_length}), OpenAIë¡œ fallback: {e}")
                if fallback_model:
                    try:
                        print("ProcessorAgent: OpenAI fallbackìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
                        fallback_chunks_received = 0
                        async for chunk in fallback_model.astream(prompt):
                            fallback_chunks_received += 1
                            yield chunk
                        print(f"ProcessorAgent: OpenAI fallback ì™„ë£Œ: {fallback_chunks_received}ê°œ ì²­í¬")
                    except Exception as fallback_error:
                        print(f"ProcessorAgent: OpenAI fallbackë„ ì‹¤íŒ¨: {fallback_error}")
                        raise fallback_error
                else:
                    print("ProcessorAgent: OpenAI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                    raise e
            else:
                print(f"ProcessorAgent: ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜: {e}")
                raise e

    async def process(self, processor_type: str, data: Any, param2: Any, param3: str, param4: str = "", yield_callback=None, state: Optional[Dict[str, Any]] = None):
        """Orchestratorë¡œë¶€í„° ë™ê¸°ì‹ ì‘ì—…ì„ ë°›ì•„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print(f"\n>> Processor ì‹¤í–‰: {processor_type}")

        if processor_type == "design_report_structure":
            selected_indexes = param2
            original_query = param3
            result = await self._design_report_structure(data, selected_indexes, original_query, state)
            yield {"type": "result", "data": result}

        elif processor_type == "create_chart_data":
            section_title = param2
            generated_content = param3
            async for result in self._create_charts(data, section_title, generated_content, yield_callback, state):
                yield result
        else:
            yield {"type": "error", "data": {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì²˜ë¦¬ íƒ€ì…: {processor_type}"}}

    async def _design_report_structure(self, data: List[SearchResult], selected_indexes: List[int], query: str, state: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ + ì„¹ì…˜ë³„ ì‚¬ìš©í•  ë°ì´í„° ì¸ë±ìŠ¤ ì„ íƒ"""

        print(f"\n>> ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì‹œì‘:")
        print(f"   ì „ì²´ ë°ì´í„°: {len(data)}ê°œ")
        print(f"   ì„ íƒëœ ì¸ë±ìŠ¤: {selected_indexes} ({len(selected_indexes)}ê°œ)")

        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¶”ì¶œ
        persona_name = state.get("persona", "ê¸°ë³¸") if state else "ê¸°ë³¸"
        persona_description = self.personas.get(persona_name, {}).get("description", "ì¼ë°˜ì ì¸ ë¶„ì„ê°€")
        print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ì— '{persona_name}' í˜ë¥´ì†Œë‚˜ ê´€ì  ì ìš©")

        # ì„ íƒëœ ì¸ë±ìŠ¤ì˜ ë°ì´í„°ë¥¼ ì¸ë±ìŠ¤ì™€ í•¨ê»˜ ë§¤í•‘í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        indexed_context = ""
        for idx in selected_indexes:
            if 0 <= idx < len(data):
                res = data[idx]
                source = getattr(res, 'source', 'Unknown')
                title = getattr(res, 'title', 'No Title')
                content = getattr(res, 'content', '')  # ì „ì²´ ë‚´ìš© (ìš”ì•½ ì—†ì´)

                indexed_context += f"""
    --- ë°ì´í„° ì¸ë±ìŠ¤ [{idx}] ---
    ì¶œì²˜: {source}
    ì œëª©: {title}
    ë‚´ìš©: {content}

    """

        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°)
        limited_indexed_context = indexed_context[:20000]  # ë” ë§ì€ ì •ë³´ í¬í•¨

        print(f"   ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(indexed_context)} ë¬¸ì")
        print(f"   ì œí•œëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(limited_indexed_context)} ë¬¸ì")

        prompt = f"""
    ë‹¹ì‹ ì€ '{persona_name}'({persona_description})ì˜ ê´€ì ì„ ê°€ì§„ ë°ì´í„° ë¶„ì„ê°€ì´ì AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì„¤ê³„ìì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ **ì„ ë³„ëœ ë°ì´í„°**ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, **'{persona_name}'ê°€ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•  ë§Œí•œ ì£¼ì œ**ë“¤ë¡œ **ë‚´ìš©ì´ ì ˆëŒ€ ì¤‘ë³µë˜ì§€ ì•ŠëŠ”** ë…¼ë¦¬ì ì¸ ë³´ê³ ì„œ ëª©ì°¨ë¥¼ ì„¤ê³„í•˜ê³  **ê° ì„¹ì…˜ë³„ë¡œ ì‚¬ìš©í•  ë°ì´í„° ì¸ë±ìŠ¤**ë¥¼ ëª…í™•íˆ ë¶„ë°°í•´ì£¼ì„¸ìš”.

    **ê°€ì¥ ì¤‘ìš”í•œ ëª©í‘œ**: ê° ë³´ê³ ì„œ ì„¹ì…˜ì´ '{persona_name}'ì˜ ê´€ì ì—ì„œ ê³ ìœ í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ê²Œ í•˜ì—¬, ë‚´ìš© ë°˜ë³µì„ ì›ì²œì ìœ¼ë¡œ ë°©ì§€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    **ì‚¬ìš©ì ì§ˆë¬¸**: "{query}"

    **ì„ ë³„ëœ ë°ì´í„° (ì¸ë±ìŠ¤ì™€ ì „ì²´ ë‚´ìš© í¬í•¨)**:
    {limited_indexed_context}

    **ì‘ì—… ì§€ì¹¨**:
    1. **ë³´ê³ ì„œ ëª©ì°¨ ì„¤ê³„**
    - ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ” 3~5ê°œì˜ **ê³ ìœ í•˜ê³  êµ¬ì²´ì ì¸ ì„¹ì…˜**ìœ¼ë¡œ ëª©ì°¨ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.
    - **í•µì‹¬ ê·œì¹™**: ê° ì„¹ì…˜ì˜ ì œëª©ì€ **ì„œë¡œ ë‹¤ë¥¸ ë¶„ì„ ê´€ì ì´ë‚˜ ì£¼ì œ**ë¥¼ ë‹¤ë£¨ì–´ì•¼ í•©ë‹ˆë‹¤. ëª¨í˜¸í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ì œëª©ì€ ì ˆëŒ€ ê¸ˆì§€ë©ë‹ˆë‹¤.

        - **ì ˆëŒ€ í”¼í•´ì•¼ í•  ë‚˜ìœ ì˜ˆì‹œ (ì£¼ì œê°€ ìœ ì‚¬í•˜ì—¬ ë‚´ìš©ì´ ì¤‘ë³µë¨):**
            - "1. ë§Œë‘ ìˆ˜ì¶œ í˜„í™© ë¶„ì„", "2. ì£¼ìš” ìˆ˜ì¶œêµ­ ë° ì‹œì¥ ë™í–¥"  (X)
            - "1. ì‹œì¥ íŠ¸ë Œë“œ", "2. ìµœì‹  ë™í–¥ ë¶„ì„" (X)

        - **ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•  ì¢‹ì€ ì˜ˆì‹œ (ì£¼ì œê°€ ëª…í™•íˆ ë¶„ë¦¬ë¨):**
            - "1. **êµ­ê°€ë³„ ìˆ˜ì¶œì•¡ ë°ì´í„°**ë¥¼ í†µí•œ í•µì‹¬ ì‹œì¥ ë¶„ì„" (ì •ëŸ‰ì , ìˆœìœ„)
            - "2. **ì†Œë¹„ì ì„ í˜¸ë„ ë° ìµœì‹  ì‹í’ˆ íŠ¸ë Œë“œ** ë¶„ì„" (ì •ì„±ì , íŠ¸ë Œë“œ)
            - "3. **ì£¼ìš” ê²½ìŸì‚¬ ì „ëµ ë° ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€** ì—°êµ¬" (ê²½ìŸ, ì‚¬ë¡€ ë¶„ì„)

    2. **ê° ì„¹ì…˜ë³„ ì‚¬ìš© ë°ì´í„° ì„ íƒ**
    - **1ë‹¨ê³„ì—ì„œ ì„¤ê³„í•œ ê³ ìœ í•œ ì„¹ì…˜ ì œëª©**ì„ ê¸°ì¤€ìœ¼ë¡œ, ê° ì„¹ì…˜ë§ˆë‹¤ `use_contents` í•„ë“œì— **í•´ë‹¹ ì„¹ì…˜ì—ì„œ ì‚¬ìš©í•  ë°ì´í„° ì¸ë±ìŠ¤ ë²ˆí˜¸ë“¤ì„ ë°°ì—´ë¡œ** í¬í•¨í•˜ì„¸ìš”.
    - **ë°ì´í„° ì¤‘ë³µ í• ë‹¹ ì—„ê²© ê¸ˆì§€**: **ì„œë¡œ ë‹¤ë¥¸ ì„¹ì…˜ì€ ë°˜ë“œì‹œ ì„œë¡œ ë‹¤ë¥¸ `use_contents` ëª©ë¡ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.** ë™ì¼í•œ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ì„¹ì…˜ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ìµœì†Œí™”í•´ì•¼ í•©ë‹ˆë‹¤.
    - **ìµœì  í• ë‹¹ ì›ì¹™**: ê° ë°ì´í„°ëŠ” ê·¸ê²ƒì´ ê°€ì¥ í•µì‹¬ì ìœ¼ë¡œ ë’·ë°›ì¹¨í•  ìˆ˜ ìˆëŠ” **ë‹¨ í•˜ë‚˜ì˜ ì„¹ì…˜ì—ë§Œ í• ë‹¹**í•˜ëŠ” ê²ƒì„ ì›ì¹™ìœ¼ë¡œ í•©ë‹ˆë‹¤.
    - **ì¸ë±ìŠ¤ ë²”ìœ„ ë° ê°œìˆ˜ ì œí•œ**:
        - ìœ„ì— ì œì‹œëœ ë°ì´í„° ì¸ë±ìŠ¤ ì¤‘ì—ì„œë§Œ ì„ íƒí•˜ì„¸ìš”: {selected_indexes}
        - í•œ ì„¹ì…˜ì— ë„ˆë¬´ ë§ì€ ë°ì´í„°(5ê°œ ì´ˆê³¼)ë¥¼ í• ë‹¹í•˜ì§€ ë§ˆì„¸ìš”.

    3. **'ê²°ë¡ ' ì„¹ì…˜ ì¶”ê°€ (í•„ìˆ˜)**: ë³´ê³ ì„œì˜ ê°€ì¥ ë§ˆì§€ë§‰ì—ëŠ” í•­ìƒ 'ê²°ë¡ ' ì„¹ì…˜ì„ í¬í•¨í•˜ì„¸ìš”.
    - `content_type`ì€ 'synthesis'ë¡œ ì„¤ì •
    - `use_contents`ì—ëŠ” ì£¼ìš” ì„¹ì…˜ë“¤ì˜ í•µì‹¬ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ í¬í•¨

    4. **ë°ì´í„° í•„ìš” ìœ í˜• ëª…ì‹œ**:
    - **ìˆ˜ì¹˜, í†µê³„, íŠ¸ë Œë“œ, ë¶„ì„ ê´€ë ¨ ì„¹ì…˜**: 'full_data_for_chart' (ì°¨íŠ¸ ìƒì„±)
    - **ì¼ë°˜ ì„¤ëª…, ê°œìš”, ê²°ë¡ **: 'synthesis' (í…ìŠ¤íŠ¸ë§Œ)

    5. **ë°ì´í„° ì¶©ë¶„ì„± ê²€ì¦**:
    - ê¸°ë³¸ì ìœ¼ë¡œ `is_sufficient`ëŠ” `true`ë¡œ ì„¤ì •
    - í•´ë‹¹ ì„¹ì…˜ ì£¼ì œì™€ ê´€ë ¨ëœ ë°ì´í„°ê°€ ì „í˜€ ì—†ëŠ” ê²½ìš°ì—ë§Œ `false`ë¡œ ì„¤ì •
    - `feedback_for_gatherer` í•„ë“œì— ì¶”ê°€ ë°ì´í„° ìš”ì²­ì´ í•„ìš”í•œ ê²½ìš°, ì •ë³´ê°€ ë¶€ì¡±í•œ ë¶€ë¶„ì€ ë³´ê°•í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”

    **ì„¹ì…˜ë³„ ë°ì´í„° ì„ íƒ ì˜ˆì‹œ**:
    - "ì‹œì¥ ê·œëª¨ ë¶„ì„" ì„¹ì…˜ â†’ ì‹œì¥, ë§¤ì¶œ, ê·œëª¨ ê´€ë ¨ ë°ì´í„° ì¸ë±ìŠ¤ë§Œ ì„ íƒ
    - "ì†Œë¹„ì íŠ¸ë Œë“œ" ì„¹ì…˜ â†’ ì†Œë¹„ì, êµ¬ë§¤, ì„ í˜¸ë„ ê´€ë ¨ ë°ì´í„° ì¸ë±ìŠ¤ë§Œ ì„ íƒ
    - "ê²°ë¡ " ì„¹ì…˜ â†’ ê° ì„¹ì…˜ì˜ í•µì‹¬ ë°ì´í„°ë“¤ì„ ì¢…í•©í•˜ì—¬ ì„ íƒ

    **ì¶œë ¥ í¬ë§· (ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ):**
    {{
        "title": "ë³´ê³ ì„œì˜ ìµœì¢… ì œëª©",
        "structure": [
            {{
                "section_title": "1. ì‹œì¥ í˜„í™© ë¶„ì„",
                "content_type": "full_data_for_chart",
                "use_contents": [0, 3, 7],
                "is_sufficient": true,
                "feedback_for_gatherer": ""
            }},
            {{
                "section_title": "2. ì†Œë¹„ì íŠ¸ë Œë“œ ë¶„ì„",
                "content_type": "full_data_for_chart",
                "use_contents": [1, 5, 9],
                "is_sufficient": true,
                "feedback_for_gatherer": ""
            }},
            {{
                "section_title": "3. ê²½ìŸ í™˜ê²½ ë¶„ì„",
                "content_type": "synthesis",
                "use_contents": [2, 4, 8],
                "is_sufficient": false,
                "feedback_for_gatherer": {{
                    "tool": "vector_db_search",
                    "query": "ì˜¤ëšœê¸° ê²½ìŸì‚¬ì˜ ì‹œì¥ ì ìœ ìœ¨ê³¼ ì „ëµ ë¶„ì„"
                }}
            }},
            {{
                "section_title": "4. ê²°ë¡ ",
                "content_type": "synthesis",
                "use_contents": [0, 1, 3, 5, 7, 9],
                "is_sufficient": true,
                "feedback_for_gatherer": ""
            }}
        ]
    }}

    **ì¤‘ìš”**: `use_contents` ë°°ì—´ì—ëŠ” ë°˜ë“œì‹œ ìœ„ì— ì œì‹œëœ ì¸ë±ìŠ¤ ë²ˆí˜¸ {selected_indexes} ì¤‘ì—ì„œë§Œ ì„ íƒí•˜ì„¸ìš”.
    """

        try:
            response = await self._invoke_with_fallback(
                prompt,
                self.llm_flash,
                self.llm_openai_mini
            )

            print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì‘ë‹µ ê¸¸ì´: {len(response.content)} ë¬¸ì")

            # JSON íŒŒì‹±
            design_result = json.loads(re.search(r'\{.*\}', response.content, re.DOTALL).group())

            # ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì¦ ë° ë””ë²„ê¹…
            print(f"  - êµ¬ì¡° ì„¤ê³„ ê²°ê³¼ ê²€ì¦:")
            for i, section in enumerate(design_result.get("structure", [])):
                section_title = section.get("section_title", f"ì„¹ì…˜ {i+1}")
                use_contents = section.get("use_contents", [])

                # ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ í•„í„°ë§
                valid_use_contents = []
                for idx in use_contents:
                    if isinstance(idx, int) and idx in selected_indexes:
                        valid_use_contents.append(idx)
                    else:
                        print(f"    ê²½ê³ : ì˜ëª»ëœ ì¸ë±ìŠ¤ {idx} ì œê±°ë¨ (í—ˆìš©ëœ ì¸ë±ìŠ¤: {selected_indexes})")

                section["use_contents"] = valid_use_contents

                print(f"    '{section_title}': {len(valid_use_contents)}ê°œ ë°ì´í„° ì‚¬ìš©")
                print(f"      ì‚¬ìš© ì¸ë±ìŠ¤: {valid_use_contents}")

                # ì‚¬ìš©ë  ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                for idx in valid_use_contents[:2]:  # ì²˜ìŒ 2ê°œë§Œ
                    if 0 <= idx < len(data):
                        data_item = data[idx]
                        print(f"      [{idx:2d}] {getattr(data_item, 'source', 'Unknown'):10s} | {getattr(data_item, 'title', 'No Title')[:40]}")

            print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì™„ë£Œ: '{design_result.get('title', 'ì œëª©ì—†ìŒ')}'")
            print(f"{design_result.get('structure', [])}")
            return design_result

        except Exception as e:
            print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì‹¤íŒ¨: {e}")
            print(f"  - ì•ˆì „ ëª¨ë“œë¡œ ê¸°ë³¸ êµ¬ì¡° ìƒì„±")

            # ì•ˆì „ ëª¨ë“œ: ëª¨ë“  ì„ íƒëœ ì¸ë±ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ì—ì„œ ì‚¬ìš©
            return {
                "title": f"{query} - í†µí•© ë¶„ì„ ë³´ê³ ì„œ",
                "structure": [{
                    "section_title": "ì¢…í•© ë¶„ì„",
                    "content_type": "synthesis",
                    "use_contents": selected_indexes[:10],  # ìµœëŒ€ 10ê°œê¹Œì§€ë§Œ
                    "is_sufficient": True,
                    "feedback_for_gatherer": ""
                }]
            }


    # worker_agents.py - ProcessorAgent í´ë˜ìŠ¤ì˜ ìˆ˜ì •ëœ í•¨ìˆ˜ë“¤

    async def _synthesize_data_for_section(self, section_title: str, section_data: List[SearchResult]) -> str:
        """â­ ìˆ˜ì •: ì„¹ì…˜ë³„ ì„ íƒëœ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì¶œì²˜ ë²ˆí˜¸ ì •í™•íˆ ë§¤í•‘"""

        # â­ í•µì‹¬ ê°œì„ : ì„¹ì…˜ë³„ ì„ íƒëœ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì¶œì²˜ ì •ë³´ ìƒì„±
        context_with_sources = ""
        for i, res in enumerate(section_data):  # section_dataë§Œ ì‚¬ìš© (all_data ëŒ€ì‹ )
            source_info = ""
            source_link = ""

            # Web search ê²°ê³¼ì¸ ê²½ìš°
            if hasattr(res, 'source') and 'web_search' in str(res.source).lower():
                if hasattr(res, 'url') and res.url:
                    source_link = res.url
                    source_info = f"ì›¹ ì¶œì²˜: {res.url}"
                elif hasattr(res, 'metadata') and res.metadata and 'link' in res.metadata:
                    source_link = res.metadata['link']
                    source_info = f"ì›¹ ì¶œì²˜: {res.metadata['link']}"
                else:
                    source_info = "ì›¹ ê²€ìƒ‰ ê²°ê³¼"
                    source_link = "ì›¹ ê²€ìƒ‰"

            # Vector DB ê²°ê³¼ì¸ ê²½ìš°
            elif hasattr(res, 'source_url'):
                source_info = f"ë¬¸ì„œ ì¶œì²˜: {res.source_url}"
                source_link = res.source_url
            elif hasattr(res, 'title'):
                source_info = f"ë¬¸ì„œ: {res.title}"
                source_link = res.title
            else:
                source_name = res.source if hasattr(res, 'source') else 'Vector DB'
                source_info = f"ì¶œì²˜: {source_name}"
                source_link = source_name

            # í•µì‹¬: ì„¹ì…˜ ë°ì´í„° ë‚´ì—ì„œì˜ ì¸ë±ìŠ¤ ì‚¬ìš© (0, 1, 2...)
            context_with_sources += f"--- ë¬¸ì„œ ID {i}: [{source_info}] ---\nì œëª©: {res.title}\në‚´ìš©: {res.content}\nì¶œì²˜_ë§í¬: {source_link}\n\n"

        prompt = f"""
    ë‹¹ì‹ ì€ ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì¢…í•©í•˜ì—¬ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ë¶„ì„ ë³´ê³ ì„œì˜ í•œ ì„¹ì…˜ì„ ì €ìˆ í•˜ëŠ” ì£¼ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    **ì‘ì„±í•  ì„¹ì…˜ì˜ ì£¼ì œ**: "{section_title}"

    **ì‚¬ìš© ë°ì´í„° ì¸ë±ìŠ¤**

    **ì°¸ê³ í•  ì„ íƒëœ ë°ì´í„°** (ì„¹ì…˜ë³„ë¡œ ì—„ì„ ëœ ê´€ë ¨ ë°ì´í„°):
    {context_with_sources[:8000]}

    **ì‘ì„± ì§€ì¹¨**:
    1. **í•µì‹¬ ì •ë³´ ì¶”ì¶œ**: '{section_title}' ì£¼ì œì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ í•µì‹¬ ì‚¬ì‹¤, ìˆ˜ì¹˜, í†µê³„ ìœ„ì£¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
    2. **ê°„ê²°í•œ ìš”ì•½**: ì •ë³´ë¥¼ ë‹¨ìˆœíˆ ë‚˜ì—´í•˜ì§€ ë§ê³ , 1~2 ë¬¸ë‹¨ ì´ë‚´ì˜ ê°„ê²°í•˜ê³  ë…¼ë¦¬ì ì¸ í•µì‹¬ ìš”ì•½ë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”.
    3. **ì¤‘ë³µ ì œê±°**: ì—¬ëŸ¬ ë¬¸ì„œì— ê±¸ì³ ë°˜ë³µë˜ëŠ” ë‚´ìš©ì€ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ì œê±°í•˜ì„¸ìš”.
    4. **ê°ê´€ì„± ìœ ì§€**: ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ê°ê´€ì ì¸ ì‚¬ì‹¤ë§Œì„ ì „ë‹¬í•´ì£¼ì„¸ìš”.
    5. **â­ ì¶œì²˜ ì •ë³´ ë³´ì¡´**: ì¤‘ìš”í•œ ì •ë³´ë‚˜ ìˆ˜ì¹˜ë¥¼ ì–¸ê¸‰í•  ë•Œ í•´ë‹¹ ì •ë³´ì˜ ì¶œì²˜ë¥¼ [SOURCE:ìˆ«ì] í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”. ë°˜ë“œì‹œ ìˆ«ìë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
    - **ë¬¸ì„œ ID ë²ˆí˜¸ë¥¼ ì‚¬ìš©**
    - ì˜ˆì‹œ: "ì‹œì¥ ê·œëª¨ê°€ ì¦ê°€í–ˆìŠµë‹ˆë‹¤ [SOURCE:1]", "ë§¤ì¶œì´ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤ [SOURCE:2]"
    - ì˜ëª»ëœ ì˜ˆì‹œ: [SOURCE:ë°ì´í„° 1], [SOURCE:ë¬¸ì„œ 1] (ì´ëŸ° í˜•ì‹ ì‚¬ìš© ê¸ˆì§€)
    6. **â­ ë…¸ì…˜ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ ì ê·¹ í™œìš©**:
    - **ì¤‘ìš”í•œ í‚¤ì›Œë“œë‚˜ ìˆ˜ì¹˜**: **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
    - *ì¼ë°˜ì ì¸ ê°•ì¡°ë‚˜ íŠ¸ë Œë“œ*: *ê¸°ìš¸ì„ì²´*ë¡œ í‘œí˜„
    - **í•µì‹¬ í¬ì¸íŠ¸ë‚˜ ê²°ë¡ **: > ì¸ìš©ë¬¸ í˜•íƒœë¡œ ê°•ì¡°
    - **í•­ëª©ì´ ì—¬ëŸ¬ ê°œ**: - ì²« ë²ˆì§¸ í•­ëª©, - ë‘ ë²ˆì§¸ í•­ëª© í˜•íƒœ
    - **í•˜ìœ„ ë¶„ë¥˜**:   - ì„¸ë¶€ í•­ëª© (ë“¤ì—¬ì“°ê¸°)
    - **ë‹¨ë½ êµ¬ë¶„**: ë‚´ìš© ë³€í™” ì‹œ ê³µë°± ë¼ì¸ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„

    **ê²°ê³¼ë¬¼ (í•µì‹¬ ìš”ì•½ë³¸)**:
    """
        response = await self._invoke_with_fallback(
            prompt,
            self.llm_flash,
            self.llm_openai_mini
        )
        return response.content

    async def generate_section_streaming(self, section: Dict[str, Any], full_data_dict: Dict[int, Dict], original_query: str, use_indexes: List[int], state: Optional[Dict[str, Any]] = None) -> AsyncGenerator[str, None]:
        """í˜ë¥´ì†Œë‚˜ë¥¼ ë°˜ì˜í•˜ì—¬ ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ì—ì„œ í•´ë‹¹ ì„¹ì…˜ ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±"""
        section_title = section.get("section_title", "ì œëª© ì—†ìŒ")
        content_type = section.get("content_type", "synthesis")
        description = section.get("description", "")

        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¶”ì¶œ
        persona_name = state.get("persona", "ê¸°ë³¸") if state else "ê¸°ë³¸"
        persona_instruction = self.personas.get(persona_name, {}).get("prompt", "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI ë¶„ì„ê°€ì…ë‹ˆë‹¤.")
        print(f"  - ì„¹ì…˜ ìƒì„±ì— '{persona_name}' í˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼ ì ìš©")

        # ì„¹ì…˜ ì‹œì‘ ì‹œ H2 í—¤ë”ë¡œ ì¶œë ¥
        section_header = f"\n\n## {section_title}\n\n"
        yield section_header

        if content_type == "synthesis":
            print(f"\nğŸ” === SECTION STREAMING ë””ë²„ê¹… ({section_title}) ===")
            print(f"use_indexes: {use_indexes}")
            print(f"full_data_dict í‚¤ë“¤: {list(full_data_dict.keys()) if full_data_dict else 'None'}")

            # ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ì—ì„œ í•´ë‹¹ ì¸ë±ìŠ¤ë§Œ ì„ ë³„í•˜ì—¬ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…
            section_data_content = ""
            valid_indexes = []
            for actual_index in use_indexes:
                if actual_index in full_data_dict:
                    valid_indexes.append(actual_index)
                    data_info = full_data_dict[actual_index]
                    section_data_content += f"**ë°ì´í„° {actual_index}: {data_info['source']}**\n"
                    section_data_content += f"- **ì œëª©**: {data_info['title']}\n"
                    section_data_content += f"- **ë‚´ìš©**: {data_info['content']}\n\n"
                    print(f"  âœ… [{actual_index}] ë°ì´í„° ë§¤í•‘ ì„±ê³µ: '{data_info['title'][:30]}...'")
                else:
                    print(f"  âŒ [{actual_index}] full_data_dictì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ!")

            print(f"ìœ íš¨í•œ ì¸ë±ìŠ¤ë“¤: {valid_indexes}")
            print(f"í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš©í•  SOURCE ë²ˆí˜¸ë“¤: {valid_indexes}")

            prompt_template = """

    {persona_instruction}

    ë‹¹ì‹ ì€ ìœ„ì˜ í˜ë¥´ì†Œë‚˜ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¼ì„œ, ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë³´ê³ ì„œì˜ í•œ ì„¹ì…˜ì„ ì‘ì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.

    **ì‚¬ìš©ìì˜ ì „ì²´ ì§ˆë¬¸**: "{original_query}"
    **í˜„ì¬ ì‘ì„±í•  ì„¹ì…˜ ì œëª©**: "{section_title}"
    **ì„¹ì…˜ ëª©í‘œ**: "{description}"

    **ì°¸ê³  ë°ì´í„° (ì‹¤ì œ ì¸ë±ìŠ¤ ë²ˆí˜¸ í¬í•¨)**:
    {section_data_content}

    **ì‘ì„± ì§€ì¹¨ (ë§¤ìš° ì¤‘ìš”)**:
    1. **í˜ë¥´ì†Œë‚˜ ì—­í•  ìœ ì§€**: ë‹¹ì‹ ì˜ ì—­í• ê³¼ ë§íˆ¬, ë¶„ì„ ê´€ì ì„ ë°˜ë“œì‹œ ìœ ì§€í•˜ë©° ì‘ì„±í•˜ì„¸ìš”.
    2. **ê°„ê²°ì„± ìœ ì§€**: ë°˜ë“œì‹œ 1~2 ë¬¸ë‹¨ ì´ë‚´ë¡œ, ê°€ì¥ í•µì‹¬ì ì¸ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
    3. **ì œëª© ë°˜ë³µ ê¸ˆì§€**: ì£¼ì–´ì§„ ì„¹ì…˜ ì œëª©ì„ ì ˆëŒ€ ë°˜ë³µí•´ì„œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ë°”ë¡œ ë³¸ë¬¸ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
    4. **ë°ì´í„° ê¸°ë°˜**: ì°¸ê³  ë°ì´í„°ì— ìˆëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì‚¬ì‹¤, ì¸ìš©êµ¬ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‚´ìš©ì„ êµ¬ì„±í•˜ì„¸ìš”.
    5. **ì „ë¬¸ê°€ì  ë¬¸ì²´**: ëª…í™•í•˜ê³  ê°„ê²°í•˜ë©° ë…¼ë¦¬ì ì¸ ì „ë¬¸ê°€ì˜ í†¤ìœ¼ë¡œ ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.
    6. **â­ ë…¸ì…˜ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ ì ê·¹ í™œìš© (ë§¤ìš° ì¤‘ìš”)**:
    - **í•µì‹¬ í‚¤ì›Œë“œë‚˜ ì¤‘ìš”í•œ ìˆ˜ì¹˜**: **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
    - *ì¼ë°˜ì ì¸ ê°•ì¡°ë‚˜ ë³€í™”*: *ê¸°ìš¸ì„ì²´*ë¡œ í‘œí˜„
    - **ì£¼ìš” í¬ì¸íŠ¸ë‚˜ ê²°ë¡ **: > ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ë‚˜ ê²°ë¡  í˜•íƒœë¡œ ê°•ì¡°
    - **ëª©ë¡ì´ í•„ìš”í•œ ê²½ìš°**: - ì²« ë²ˆì§¸ í•­ëª©, - ë‘ ë²ˆì§¸ í•­ëª© í˜•íƒœë¡œ êµ¬ì¡°í™”
    - **í•˜ìœ„ ë¶„ë¥˜ê°€ ìˆëŠ” ê²½ìš°**:   - ì„¸ë¶€ í•­ëª© (ë“¤ì—¬ì“°ê¸° ì‚¬ìš©)
    - **ì„¸ë¶€ ì¹´í…Œê³ ë¦¬**: ### ì†Œì œëª© í™œìš©
    - **ë‹¨ë½ êµ¬ë¶„**: ë‚´ìš©ì´ ë°”ë€” ë•Œë§ˆë‹¤ ëª…í™•í•˜ê²Œ ë‹¨ë½ì„ ë‚˜ëˆ„ì–´ ê³µë°± ë¼ì¸ ì‚½ì…
    7. **â­ ì¶œì²˜ í‘œê¸° (ì‹¤ì œ ì¸ë±ìŠ¤ ë²ˆí˜¸ ì‚¬ìš©)**: íŠ¹ì • ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•œ ë¬¸ì¥ ë°”ë¡œ ë’¤ì— [SOURCE:ìˆ«ì] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ í‘œê¸°í•˜ì„¸ìš”. ë°˜ë“œì‹œ ìˆ«ìë§Œ ì‚¬ìš©í•˜ê³  "ë°ì´í„°"ë¼ëŠ” ë‹¨ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    - ì˜ˆì‹œ: "**ë§¤ì¶œì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤** [SOURCE:8]", "ì‹œì¥ ì ìœ ìœ¨ì´ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤ [SOURCE:12]"
    - ì˜ˆì‹œ: **ë§¤ì¶œì´ 5% ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤. [SOURCE:1, 4, 8]
    - ì˜ëª»ëœ ì˜ˆì‹œ: [SOURCE:ë°ì´í„° 1], [SOURCE:ë¬¸ì„œ 1] (ì´ëŸ° í˜•ì‹ ì‚¬ìš© ê¸ˆì§€)

    **ë³´ê³ ì„œ ì„¹ì…˜ ë‚´ìš©**:
    """

            prompt = prompt_template.format(
                persona_instruction=persona_instruction,
                original_query=original_query,
                section_title=section_title,
                description=description,
                section_data_content=section_data_content
            )

        else:  # "full_data_for_chart"
            section_data_with_sources = ""
            for actual_index in use_indexes:
                if actual_index in full_data_dict:
                    data_info = full_data_dict[actual_index]
                    section_data_with_sources += f"**ë°ì´í„° {actual_index}: {data_info['source']}**\n"
                    section_data_with_sources += f"- **ì œëª©**: {data_info['title']}\n"
                    section_data_with_sources += f"- **ë‚´ìš©**: {data_info['content']}\n"
                    section_data_with_sources += f"- **ì¶œì²˜_ë§í¬**: {data_info.get('url') or data_info.get('source_url', '')}\n\n"

            prompt_template = """
    ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ê°€ì´ì ë³´ê³ ì„œ ì‘ì„±ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì„ íƒëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, í…ìŠ¤íŠ¸ ì„¤ëª…ê³¼ ì‹œê°ì  ì°¨íŠ¸ë¥¼ ê²°í•©í•œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë³´ê³ ì„œ ì„¹ì…˜ì„ ì‘ì„±í•©ë‹ˆë‹¤.

    **ì‚¬ìš©ìì˜ ì „ì²´ ì§ˆë¬¸**: "{original_query}"
    **í˜„ì¬ ì‘ì„±í•  ì„¹ì…˜ ì œëª©**: "{section_title}"
    **ì„¹ì…˜ ëª©í‘œ**: "{description}"

    **ì°¸ê³  ë°ì´í„° (ì‹¤ì œ ì¸ë±ìŠ¤ ë²ˆí˜¸ í¬í•¨)**:
    {section_data}

    **ì‘ì„± ì§€ì¹¨ (ë§¤ìš° ì¤‘ìš”)**:
    1. **ê°„ê²°ì„± ìœ ì§€**: ë°˜ë“œì‹œ 1~2 ë¬¸ë‹¨ ì´ë‚´ë¡œ, ë°ì´í„°ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ì™€ ë¶„ì„ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
    2. **ì œëª© ë°˜ë³µ ê¸ˆì§€**: ì£¼ì–´ì§„ ì„¹ì…˜ ì œëª©ì„ ì ˆëŒ€ ë°˜ë³µí•´ì„œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ë°”ë¡œ ë³¸ë¬¸ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
    3. **ë°ì´í„° ê¸°ë°˜**: ì„¤ëª…ì— êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì‚¬ì‹¤, í†µê³„ ìë£Œë¥¼ ì ê·¹ì ìœ¼ë¡œ ì¸ìš©í•˜ì—¬ ì‹ ë¢°ë„ë¥¼ ë†’ì´ì„¸ìš”.
    4. **â­ ì°¨íŠ¸ ë§ˆì»¤ ì‚½ì…**: í…ìŠ¤íŠ¸ ì„¤ëª…ì˜ íë¦„ ìƒ, ì‹œê°ì  ë°ì´í„°ê°€ í•„ìš”í•œ ì ì ˆí•œ ìœ„ì¹˜ì— [GENERATE_CHART] ë§ˆì»¤ë¥¼ í•œ ì¤„ì— ë‹¨ë…ìœ¼ë¡œ ì‚½ì…í•˜ì„¸ìš”.
    5. **ì„œìˆ  ê³„ì†**: ë§ˆì»¤ë¥¼ ì‚½ì…í•œ í›„, ì´ì–´ì„œ ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ìì—°ìŠ¤ëŸ½ê²Œ ê³„ì† ì‘ì„±í•˜ì„¸ìš”.
    6. **â­ ë…¸ì…˜ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ ì ê·¹ í™œìš©**: êµµì€ ê¸€ì”¨, ê¸°ìš¸ì„ì²´, ì¸ìš©ë¬¸, ëª©ë¡ ë“±ì„ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”.
    7. **â­ ì¶œì²˜ í‘œê¸° (ì‹¤ì œ ì¸ë±ìŠ¤ ë²ˆí˜¸ ì‚¬ìš©)**: íŠ¹ì • ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•œ ë¬¸ì¥ ë°”ë¡œ ë’¤ì— [SOURCE:ìˆ«ì1, ìˆ«ì2, ìˆ«ì3] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ í‘œê¸°í•˜ì„¸ìš”. ë°˜ë“œì‹œ ìˆ«ìë§Œ ì‚¬ìš©í•˜ê³  "ë°ì´í„°", "ë¬¸ì„œ" ë“±ì˜ ë‹¨ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    - ì˜ˆì‹œ: **ì‹œì¥ ê·œëª¨ê°€ 10% ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. [SOURCE:8]
    - ì˜ˆì‹œ: **ë§¤ì¶œì´ 5% ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤. [SOURCE:1, 4, 8]
    - ì˜ëª»ëœ ì˜ˆì‹œ: [SOURCE:ë°ì´í„° 8], [SOURCE:ë¬¸ì„œ 8] (ì´ëŸ° í˜•ì‹ ì‚¬ìš© ê¸ˆì§€)

    **ë³´ê³ ì„œ ì„¹ì…˜ ë³¸ë¬¸**:
    """

            prompt = prompt_template.format(
                persona_instruction=persona_instruction,
                original_query=original_query,
                section_title=section_title,
                description=description,
                section_data=section_data_with_sources
            )

        try:
            print(f"\n>> ì„¹ì…˜ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: {section_title} (ì‚¬ìš© ì¸ë±ìŠ¤: {use_indexes})")
            total_content = ""
            chunk_count = 0
            valid_content_count = 0

            async for chunk in self._astream_with_fallback(
                prompt,
                self.llm_pro,
                self.llm_openai_4o
            ):
                chunk_count += 1
                if hasattr(chunk, 'content') and chunk.content:
                    total_content += chunk.content
                    chunk_text = chunk.content
                    valid_content_count += 1

                    print(f"- ì›ë³¸ ì²­í¬ {chunk_count}: {len(chunk_text)} ë¬¸ì")

                    # 5ì ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ì „ì†¡
                    for i in range(0, len(chunk_text), 5):
                        mini_chunk = chunk_text[i:i+5]
                        yield mini_chunk

            print(f"\n>> ì„¹ì…˜ ì™„ë£Œ: {section_title}, ì´ {chunk_count}ê°œ ì›ë³¸ ì²­í¬, {valid_content_count}ê°œ ìœ íš¨ ì²­í¬, {len(total_content)} ë¬¸ì")

            if not total_content.strip() or valid_content_count == 0:
                print(f"- ì„¹ì…˜ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜ ({section_title}): No generation chunks were returned")
                raise Exception("No generation chunks were returned")

        except Exception as e:
            print(f"- ì„¹ì…˜ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜ ({section_title}): {e}")
            if "No generation chunks" in str(e) or "no valid content" in str(e).lower():
                try:
                    print(f"- OpenAIë¡œ ì§ì ‘ ì¬ì‹œë„: {section_title}")
                    total_content = ""
                    chunk_count = 0

                    async for chunk in self.llm_openai_4o.astream(prompt):
                        chunk_count += 1
                        if hasattr(chunk, 'content') and chunk.content:
                            total_content += chunk.content
                            chunk_text = chunk.content
                            print(f"- OpenAI ì¬ì‹œë„ ì²­í¬ {chunk_count}: {len(chunk_text)} ë¬¸ì")

                            for i in range(0, len(chunk_text), 5):
                                mini_chunk = chunk_text[i:i+5]
                                yield mini_chunk

                    print(f"- OpenAI ì¬ì‹œë„ ì™„ë£Œ: {section_title}, {chunk_count}ê°œ ì²­í¬, {len(total_content)} ë¬¸ì")

                    if not total_content.strip():
                        print(f"- OpenAI ì¬ì‹œë„ë„ ì‹¤íŒ¨, fallback ë‚´ìš© ìƒì„±")
                        raise Exception("OpenAI retry also failed")

                except Exception as retry_error:
                    print(f"- OpenAI ì¬ì‹œë„ ì‹¤íŒ¨: {retry_error}")
                    fallback_content = f"*'{section_title}' ì„¹ì…˜ì— ëŒ€í•œ ìƒì„¸í•œ ë¶„ì„ì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.*\n\n"
                    yield fallback_content
            else:
                error_content = f"*'{section_title}' ì„¹ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}*\n\n"
                yield error_content

    async def _create_charts(self, section_data: List[SearchResult], section_title: str, generated_content: str = "", yield_callback=None, state: Dict[str, Any] = None):
        """â­ ìˆ˜ì •: í˜ë¥´ì†Œë‚˜ ê´€ì ì„ ë°˜ì˜í•˜ì—¬ ì„¹ì…˜ë³„ ì„ íƒëœ ë°ì´í„°ì™€ ìƒì„±ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì°¨íŠ¸ ìƒì„±"""
        print(f"  - ì°¨íŠ¸ ë°ì´í„° ìƒì„±: '{section_title}' (ë°ì´í„° {len(section_data)}ê°œ)")

        # >> ë°ì´í„° ë³´ê°•ì„ ìœ„í•œ DataGatherer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        from .worker_agents import DataGathererAgent
        data_gatherer = DataGathererAgent() if not hasattr(self, 'data_gatherer') else self.data_gatherer

        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¶”ì¶œ
        persona_name = state.get("persona", "ê¸°ë³¸") if state else "ê¸°ë³¸"
        print(f"  - ì°¨íŠ¸ ìƒì„±ì— '{persona_name}' í˜ë¥´ì†Œë‚˜ ê´€ì  ì ìš©")

        async def _generate_chart_with_data(current_data: List[SearchResult], attempt: int = 1):
            """ì‹¤ì œ ì°¨íŠ¸ ìƒì„± ë¡œì§ (ì¬ì‹œë„ ê°€ëŠ¥)"""
            try:
                # ë°ì´í„° ìš”ì•½ ìƒì„±
                data_summary = ""
                for i, item in enumerate(current_data):
                    source = getattr(item, 'source', 'Unknown')
                    title = getattr(item, 'title', 'No Title')
                    content = getattr(item, 'content', '')[:500]
                    data_summary += f"[{i}] [{source}] {title}\në‚´ìš©: {content}...\n\n"

                # ì§ì „ì— ìƒì„±ëœ ë³´ê³ ì„œ ë‚´ìš© ì¶”ê°€
                context_info = ""
                if generated_content:
                    content_preview = generated_content[:800] if generated_content else ""
                    context_info = f"\n**ì§ì „ì— ìƒì„±ëœ ë³´ê³ ì„œ ë‚´ìš© (ì°¨íŠ¸ì™€ ì¼ë§¥ìƒí†µí•´ì•¼ í•¨)**:\n{content_preview}\n"

                chart_prompt = f"""
        CRITICAL: You MUST respond with ONLY valid JSON. No explanations, no markdown, no other text.

        '{persona_name}'ì˜ ê´€ì ì—ì„œ ë‹¤ìŒ ì„¹ì…˜ì„ ìœ„í•´ **ì„ ë³„ëœ ì‹¤ì œ ë°ì´í„°**ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì •í™•í•˜ê³  ë³µì¡í•œ**, **ê°€ì¥ í¥ë¯¸ë¡­ê³  ìœ ìš©í•œ** Chart.js ì°¨íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        (ì˜ˆ: êµ¬ë§¤ ë‹´ë‹¹ìëŠ” 'ì›ê°€ ë³€ë™' ë¼ì¸ ì°¨íŠ¸, ë§ˆì¼€í„°ëŠ” 'ì†Œë¹„ì ê´€ì‹¬ë„' ë²„ë¸” ì°¨íŠ¸ë¥¼ ì„ í˜¸í•  ê²ƒì…ë‹ˆë‹¤.)

        **ì„¹ì…˜ ì œëª©**: "{section_title}"
        **ì‹œë„ íšŸìˆ˜**: {attempt} (ìµœëŒ€ 2íšŒ)

        **ì„¹ì…˜ë³„ë¡œ ì—„ì„ ëœ ì‹¤ì œ ë°ì´í„°**:
        {data_summary}
        {context_info}

        **â­ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­**:
        1. **ì ˆëŒ€ ì„ì˜ ìˆ˜ì¹˜ ìƒì„± ê¸ˆì§€** - ìœ„ ë°ì´í„°ì—ì„œ ëª…ì‹œëœ ì‹¤ì œ ìˆ˜ì¹˜ë§Œ ì‚¬ìš©
        2. **'{persona_name}'ì˜ ê´€ì  ë°˜ì˜** - í•´ë‹¹ í˜ë¥´ì†Œë‚˜ê°€ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•  ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì„¸ìš”.
        3. **ì„¹ì…˜ ì œëª©ê³¼ ì§ì ‘ ê´€ë ¨ëœ ì°¨íŠ¸ë§Œ** ìƒì„±
        4. **ë³µì¡í•˜ê³  ìƒì„¸í•œ ì°¨íŠ¸** ìƒì„± (ìµœì†Œ 3ê°œ ì´ìƒì˜ ë°ì´í„° í¬ì¸íŠ¸)
        5. **ì •í™•í•œ ë¼ë²¨ê³¼ ìˆ˜ì¹˜** ì‚¬ìš©

        **ë°ì´í„° ì¶”ì¶œ ê·œì¹™**:
        - ìœ„ ë°ì´í„°ì—ì„œ ìˆ«ì, í¼ì„¼íŠ¸, ê¸ˆì•¡ ë“± ìˆ˜ì¹˜ ì •ë³´ ì¶”ì¶œ
        - ì—°ë„, ì›”, ë¶„ê¸° ë“± ì‹œê°„ ì •ë³´ ì¶”ì¶œ
        - ì¹´í…Œê³ ë¦¬, ë¶€ë¬¸, ì§€ì—­ ë“± ë¶„ë¥˜ ì •ë³´ ì¶”ì¶œ

        **ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš°, ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë¶€ì¡±í•œ ë°ì´í„° ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”**:
        {{
            "insufficient_data": true,
            "missing_info": "êµ¬ì²´ì ìœ¼ë¡œ ë¶€ì¡±í•œ ë°ì´í„° ì„¤ëª… (ì˜ˆ: 'ê¸€ë¡œë²Œ ì‹í’ˆ ì‹œì¥ì˜ ì—°ë„ë³„ ë§¤ì¶œì•¡ ë°ì´í„°', 'ì£¼ìš” êµ­ê°€ë³„ ì‹œì¥ ì ìœ ìœ¨ ìˆ˜ì¹˜' ë“±)",
            "suggested_search_query": "ë¶€ì¡±í•œ ë°ì´í„°ë¥¼ ì°¾ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬"
        }}

        **ë°ì´í„°ê°€ ì¶©ë¶„í•œ ê²½ìš°, Chart.js í˜•ì‹ì˜ ì™„ì „í•œ JSONì„ ì¶œë ¥í•˜ì„¸ìš”**:
        {{
            "type": "ì ì ˆí•œ_ì°¨íŠ¸_íƒ€ì…",
            "data": {{
                "labels": ["ì‹¤ì œ_ë°ì´í„°_ê¸°ë°˜_ë¼ë²¨1", "ë¼ë²¨2", "ë¼ë²¨3"],
                "datasets": [{{
                    "label": "ì‹¤ì œ_ë°ì´í„°ì…‹_ì´ë¦„",
                    "data": [ì‹¤ì œ_ìˆ˜ì¹˜1, ì‹¤ì œ_ìˆ˜ì¹˜2, ì‹¤ì œ_ìˆ˜ì¹˜3],
                    "backgroundColor": ["#4F46E5", "#7C3AED", "#EC4899"],
                    "borderColor": "#4F46E5",
                    "borderWidth": 2
                }}]
            }},
            "options": {{
                "responsive": true,
                "plugins": {{
                    "title": {{
                        "display": true,
                        "text": "{section_title} - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì°¨íŠ¸"
                    }},
                    "legend": {{
                        "display": true,
                        "position": "top"
                    }}
                }},
                "scales": {{
                    "y": {{
                        "beginAtZero": true,
                    }}
                }}
            }}
        }}

        OUTPUT ONLY JSON (no other text):
        """

                response = await self._invoke_with_fallback(
                    chart_prompt,
                    self.llm_flash,
                    self.llm_openai_mini
                )
                response_text = response.content.strip()

                # JSON ì¶”ì¶œ ê°œì„ 
                try:
                    # ì½”ë“œ ë¸”ë¡ ì œê±°
                    if "```json" in response_text:
                        response_text = response_text.split("```json")[1].split("```")[0].strip()
                    elif "```" in response_text:
                        response_text = response_text.split("```")[1].split("```")[0].strip()

                    # JSON íŒŒì‹±
                    chart_response = json.loads(response_text)

                    # >> ë°ì´í„° ë¶€ì¡± ì—¬ë¶€ í™•ì¸
                    if chart_response.get("insufficient_data", False) and attempt == 1:
                        missing_info = chart_response.get("missing_info", "")
                        search_query = chart_response.get("suggested_search_query", "")

                        print(f"  - ì°¨íŠ¸ ë°ì´í„° ë¶€ì¡± ê°ì§€: {missing_info}")
                        print(f"  - ì¶”ê°€ ê²€ìƒ‰ ì‹¤í–‰: '{search_query}'")

                        yield {
                            "type": "status",
                            "data": {"message": f"ì°¨íŠ¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ '{search_query[:50]}...' ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ê°€ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤"}
                        }

                        # >> ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘
                        try:
                            additional_data = []
                            web_results, _ = await data_gatherer.execute("web_search", {"query": search_query})
                            vector_results, _ = await data_gatherer.execute("vector_db_search", {"query": search_query})
                            additional_data.extend(web_results)
                            additional_data.extend(vector_results)

                            if additional_data:
                                print(f"  - ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(additional_data)}ê°œ")

                                # >> í”„ë¡ íŠ¸ì—”ë“œì— ê²€ìƒ‰ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
                                if additional_data:
                                    yield {
                                        "type": "status",
                                        "data": {"message": f"ì¶”ê°€ ë°ì´í„° {len(additional_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ. ì°¨íŠ¸ë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤..."}
                                    }
                                    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                    formatted_results = []
                                    for search_result in additional_data:
                                        # SearchResult ê°ì²´ì¸ì§€ dictì¸ì§€ í™•ì¸
                                        if hasattr(search_result, 'model_dump'):
                                            result_dict = search_result.model_dump()
                                        elif isinstance(search_result, dict):
                                            result_dict = search_result
                                        else:
                                            continue  # ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì€ ê±´ë„ˆë›°ê¸°

                                        formatted_result = {
                                            "title": result_dict.get("title", "ì œëª© ì—†ìŒ"),
                                            "content_preview": result_dict.get("content", "ë‚´ìš© ì—†ìŒ")[:200] + "...",
                                            "url": result_dict.get("url", "URL ì—†ìŒ"),
                                            "source": result_dict.get("source", "web_search"),
                                            "score": result_dict.get("score", 0.0),
                                            "document_type": result_dict.get("document_type", "web")
                                        }
                                        formatted_results.append(formatted_result)

                                    # ê²€ìƒ‰ ê²°ê³¼ ì´ë²¤íŠ¸ ì „ì†¡ (ì¤‘ê°„ ê²€ìƒ‰ í‘œì‹œ)
                                    yield {
                                        "type": "search_results",
                                        "data": {
                                            "step": f"chart_enhancement_{attempt}",
                                            "tool_name": "web_search",
                                            "query": search_query,
                                            "results": formatted_results,
                                            "is_intermediate_search": True,
                                            "section_context": {
                                                "section_title": section_title,
                                                "search_reason": "ì°¨íŠ¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì¶”ê°€ ê²€ìƒ‰",
                                                "attempt": attempt
                                            },
                                            "message_id": state.get("message_id") if state else None
                                        }
                                    }

                                    # ë°ì´í„° ë³´ê°• ì™„ë£Œ ìƒíƒœ ì „ì†¡
                                    yield {
                                        "type": "status",
                                        "data": {"message": f"ì°¨íŠ¸ ë°ì´í„° ë³´ê°• ì™„ë£Œ. ì°¨íŠ¸ë¥¼ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤."}
                                    }
                            else:
                                print(f"  - ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                                yield {
                                    "type": "status",
                                    "data": {"message": "ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°ì´í„°ë¡œ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."}
                                }
                        except Exception as search_error:
                            print(f"  - ë°ì´í„° ë³´ê°• ê²€ìƒ‰ ì‹¤íŒ¨: {search_error}")
                            yield {
                                "type": "status",
                                "data": {"message": f"ë°ì´í„° ë³´ê°• ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(search_error)}"}
                            }

                        # ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ fallback ì°¨íŠ¸ ë°˜í™˜
                        yield {
                            "type": "chart",
                            "data": {
                                "type": "bar",
                            "data": {
                                "labels": ["ë°ì´í„° ë¶€ì¡±"],
                                "datasets": [{
                                    "label": "ì •ë³´ ìˆ˜ì§‘ ìƒíƒœ",
                                    "data": [1],
                                    "backgroundColor": "rgba(255, 193, 7, 0.6)",
                                    "borderColor": "rgba(255, 193, 7, 1)",
                                    "borderWidth": 1
                                }]
                            },
                            "options": {
                                "responsive": True,
                                "plugins": {
                                    "title": {
                                        "display": True,
                                        "text": f"{section_title} - ë°ì´í„° ìˆ˜ì§‘ ì¤‘"
                                    }
                                }
                            }
                            }
                        }
                        return

                    # >> ì •ìƒì ì¸ ì°¨íŠ¸ ë°ì´í„°ì¸ ê²½ìš°
                    elif "type" in chart_response and "data" in chart_response:
                        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                        datasets = chart_response.get("data", {}).get("datasets", [])
                        if datasets and len(datasets) > 0:
                            data_points = datasets[0].get("data", [])
                            if len(data_points) < 2:
                                print(f"  - ê²½ê³ : ì°¨íŠ¸ ë°ì´í„° í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•¨ ({len(data_points)}ê°œ)")

                        # ì½œë°± í•¨ìˆ˜ ì œê±° (í”„ë¡ íŠ¸ì—”ë“œ ì˜¤ë¥˜ ë°©ì§€)
                        def remove_callbacks(obj):
                            if isinstance(obj, dict):
                                # ì½œë°± í•¨ìˆ˜ ê´€ë ¨ í‚¤ë“¤ ì œê±°
                                callback_keys = ['callback', 'callbacks', 'generateLabels']
                                for key in list(obj.keys()):
                                    if key in callback_keys:
                                        del obj[key]
                                    elif isinstance(obj[key], str) and 'function' in obj[key]:
                                        del obj[key]
                                    else:
                                        remove_callbacks(obj[key])
                            elif isinstance(obj, list):
                                for item in obj:
                                    remove_callbacks(item)

                        remove_callbacks(chart_response)

                        print(f"  - ì°¨íŠ¸ ìƒì„± ì„±ê³µ: {chart_response['type']} íƒ€ì…, {len(datasets)}ê°œ ë°ì´í„°ì…‹ (ì‹œë„ {attempt})")
                        yield {
                            "type": "chart",
                            "data": chart_response
                        }
                        return
                    else:
                        raise ValueError("ì˜¬ë°”ë¥´ì§€ ì•Šì€ JSON í˜•ì‹")

                except (json.JSONDecodeError, ValueError) as e:
                    print(f"  - ì°¨íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt}): {e}")
                    print(f"  - ì›ë³¸ ì‘ë‹µ: {response_text[:200]}...")

                    # ì²« ë²ˆì§¸ ì‹œë„ì´ê³  íŒŒì‹± ì‹¤íŒ¨ì‹œì—ë„ ì›¹ ê²€ìƒ‰ ì‹œë„
                    if attempt == 1:
                        print(f"  - JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ ë°ì´í„° ë³´ê°• ì‹œë„")

                        # ì„¹ì…˜ ì œëª© ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
                        fallback_query = f"{section_title} ì‹œì¥ ë°ì´í„° í†µê³„ ìˆ˜ì¹˜"

                        try:
                            # async generatorë¥¼ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬
                            additional_data, _ = await data_gatherer.execute("web_search", {"query": fallback_query})

                            if additional_data:
                                print(f"  - Fallback ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘: {len(additional_data)}ê°œ")
                                enhanced_data = current_data + additional_data
                                async for result in _generate_chart_with_data(enhanced_data, attempt=2):
                                    yield result
                                return
                        except Exception as search_error:
                            print(f"  - Fallback ê²€ìƒ‰ ì‹¤íŒ¨: {search_error}")

                    # ìµœì¢… fallback ì°¨íŠ¸
                    yield {
                        "type": "chart",
                        "data": {
                            "type": "bar",
                            "data": {
                                "labels": [f"{section_title} ê´€ë ¨ ë°ì´í„°"],
                                "datasets": [{
                                    "label": "ì •ë³´ ìˆ˜ì§‘ ìƒíƒœ",
                                    "data": [1],
                                    "backgroundColor": "rgba(255, 193, 7, 0.6)",
                                    "borderColor": "rgba(255, 193, 7, 1)",
                                    "borderWidth": 1
                                }]
                            },
                            "options": {
                                "responsive": True,
                                "plugins": {
                                    "title": {
                                        "display": True,
                                        "text": f"{section_title} - ë°ì´í„° ë¶„ì„ ì¤‘"
                                    }
                                },
                                "scales": {
                                    "y": {
                                        "beginAtZero": True,
                                        "max": 2,
                                        "ticks": {
                                            "stepSize": 1
                                        }
                                    }
                                }
                            }
                        }
                    }

            except Exception as e:
                print(f"  - ì°¨íŠ¸ ìƒì„± ì „ì²´ ì˜¤ë¥˜ (ì‹œë„ {attempt}): {e}")
                yield {
                    "type": "chart",
                    "data": {
                        "type": "bar",
                        "data": {
                            "labels": ["ì‹œìŠ¤í…œ ì˜¤ë¥˜"],
                            "datasets": [{
                                "label": "ì²˜ë¦¬ ìƒíƒœ",
                                "data": [0],
                                "backgroundColor": "rgba(220, 53, 69, 0.6)",
                                "borderColor": "rgba(220, 53, 69, 1)",
                                "borderWidth": 1
                            }]
                        },
                        "options": {
                            "responsive": True,
                            "plugins": {
                                "title": {
                                    "display": True,
                                    "text": "ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
                                }
                            }
                        }
                    }
                }

        # >> ë©”ì¸ ë¡œì§ ì‹¤í–‰
        async for result in _generate_chart_with_data(section_data, attempt=1):
            yield result
